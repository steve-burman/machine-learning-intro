{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow-SXB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/steve-burman/machine-learning-intro/blob/master/TensorFlow_SXB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idb4wKK5JNH0",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning / AI Workbench\n",
        "* Steve Burman\n",
        "* architect & developer at Jeppesen, Inc\n",
        "* 303-249-1177\n",
        "* steve.burman@jeppesen.com\n",
        "\n",
        "---\n",
        "\n",
        "**Run this section to setup:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AriwKzLQPDKc",
        "colab_type": "code",
        "outputId": "d36be476-81bd-403f-8c15-294b82856579",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "# Define common functions\n",
        "message = \"Welcome to Steve's Machine Learning / AI Workbench\"\n",
        "print( message )\n",
        "\n",
        "import datetime\n",
        "from urllib.request import urlretrieve\n",
        "import numpy as np\n",
        "from numpy import loadtxt\n",
        "from sklearn.utils import Bunch\n",
        "from sklearn.model_selection import train_test_split\n",
        "import graphviz\n",
        "\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "import  tensorflow  as  tf\n",
        "print( \"tf.__version__:\", tf.__version__ )\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "\n",
        "# analyze dataset\n",
        "def analyze_dataset(bunch):\n",
        "  print( \"Dataset details::\" )\n",
        "  print( \"feature_names = \", bunch.feature_names )\n",
        "  print( \"target_names = \", bunch.target_names )\n",
        "  # print( \"DESCR = \", bunch.DESCR[0:20] )\n",
        "  print( \"data[0:4] = \", bunch.data[0:4] )\n",
        "  print( \"target[0:4] = \", bunch.target[0:4] )\n",
        "\n",
        "def load_pima_diabetes():\n",
        "  # https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
        "  # https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.names\n",
        "  bunch = Bunch()\n",
        "  bunch.target_names = [ 'Class 0', 'Class 1']\n",
        "  bunch.feature_names = [\n",
        "      'Times pregnant'\n",
        "    , 'Plasma glucose concentration'\n",
        "    , 'Diastolic blood pressure (mm Hg)'\n",
        "    , 'Triceps skin fold thickness (mm)'\n",
        "    , '2-Hour serum insulin (mu U/ml)'\n",
        "    , 'Body mass index (weight in kg/(height in m)^2)'\n",
        "    , 'Diabetes pedigree function'\n",
        "    , 'Age (years)'\n",
        "  ]\n",
        "  urlretrieve( url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
        "    , filename=\"pima-indians-diabetes.csv\" )\n",
        "  dataset = loadtxt('pima-indians-diabetes.csv', delimiter=',')\n",
        "  bunch.data = dataset[:,0:8]\n",
        "  bunch.target = dataset[:,8]\n",
        "  return bunch\n",
        "\n",
        "print( \"Setup complete\" )"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to Steve's Machine Learning / AI Workbench\n",
            "TensorFlow 2.x selected.\n",
            "tf.__version__: 2.1.0\n",
            "Setup complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GT3N0ViMyrL",
        "colab_type": "text"
      },
      "source": [
        "### Load Iris dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15ybAivfM2MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "ff53fcbd-582b-436b-ec71-b04cef83042c"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris_dataset = load_iris()\n",
        "analyze_dataset( iris_dataset )\n",
        "# print( \"iris_dataset:\", iris_dataset )\n",
        "for i in range( len( iris_dataset.target_names ) ):\n",
        "  print( \"Example: %d: label %s, features %s\" % ( i, iris_dataset.target_names[i], iris_dataset.data[i] ) )\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset details::\n",
            "feature_names =  ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "target_names =  ['setosa' 'versicolor' 'virginica']\n",
            "data[0:4] =  [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]]\n",
            "target[0:4] =  [0 0 0 0]\n",
            "Example: 0: label setosa, features [5.1 3.5 1.4 0.2]\n",
            "Example: 1: label versicolor, features [4.9 3.  1.4 0.2]\n",
            "Example: 2: label virginica, features [4.7 3.2 1.3 0.2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cqOS_qjVwKW",
        "colab_type": "text"
      },
      "source": [
        "### Load Hand-written digits dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3XWHVH3Vr6w",
        "colab_type": "text"
      },
      "source": [
        "[MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset, which is ~60K \"Labelled\" image files of hand-written digits.\n",
        "\n",
        "![MNIST dataset](https://miro.medium.com/max/479/1*yBdJCRwIJGoM7pwU-LNW6Q.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aejLxBYwX5Y9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load MNIST dataset\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
        "\n",
        "print( \"MNIST dataset loaded\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BENBfJesNU6w",
        "colab_type": "text"
      },
      "source": [
        "### Load Pima Indians diabetes dataset\n",
        "Collaboration with Doug Eglseder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P3tAUF6SXPVG",
        "colab_type": "text"
      },
      "source": [
        "Reference: [Jason Brownlee PhD](https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/)\n",
        "\n",
        "![Pima Indians](https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2016/04/Tour-of-Deep-Learning-Algorithms.jpg)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41JnBlnbNbzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load Pima dataset\n",
        "pima_diabetes_dataset = load_pima_diabetes()\n",
        "analyze_dataset( pima_diabetes_dataset )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSGw2h8Gh0QX",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression\n",
        "best fit using objective function:  y = m * x + b"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIGzJ2pSI-FD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import  matplotlib.pyplot  as plt\n",
        "\n",
        "%tensorflow_version  2.x\n",
        "import  tensorflow  as  tf\n",
        "print( tf.__version__ )\n",
        "\n",
        "from  tensorflow.keras  import Model\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "def  createSimulatedData( m=0.1, b=0.3, n=100, stddev=0.1 ):\n",
        "  x = tf.random.uniform( shape=( n, ) )\n",
        "  noise = tf.random.normal( shape=( len(x), ), stddev=stddev )\n",
        "  y = m * x + b + noise\n",
        "  return x, y\n",
        "\n",
        "def calculateLineSlope(x1, y1, x2, y2):\n",
        "  dx = x2 - x1\n",
        "  dy = y2 - y1\n",
        "  m = dy / dx\n",
        "  return m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvnFPOZ7qpvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = calculateLineSlope( 6.9528, 46.3015, 7.0458, 46.1395 )\n",
        "x_train, y_train = createSimulatedData( m, 46.3015, 200 )\n",
        "plt.plot( x_train, y_train, 'b.' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rGQHGCPXCls",
        "colab_type": "text"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWOTaoRshQqs",
        "colab_type": "text"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yt-C7jHQXbyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import tree\n",
        "\n",
        "# Train classifier\n",
        "def train_DecisionTreeClassifier( dataset ):\n",
        "  # set aside some of dataset as train_data and some as test_data (X=data, y=target)\n",
        "  train_data, test_data, train_target, test_target = train_test_split( dataset.data, dataset.target, test_size=0.25, random_state=42 )\n",
        "  print( \"train_data[:5]:\", train_data[:5] )\n",
        "  print( \"test_data[:5]:\", test_data[:5] )\n",
        "  print( \"train_target:\", train_target )\n",
        "  print( \"test_target:\", test_target )\n",
        "  # build Decision Tree Classifier\n",
        "  classifier = tree.DecisionTreeClassifier()\n",
        "  estimator = classifier.fit( train_data, train_target )\n",
        "  return train_data, test_data, train_target, test_target, classifier\n",
        "\n",
        "def visualize_decision_tree(classifier, dataset):\n",
        "  # tree.plot_tree( classifier.fit( dataset.data, dataset.target ) )\n",
        "  dot_data = tree.export_graphviz( classifier, out_file=None,\n",
        "                      feature_names=dataset.feature_names,\n",
        "                      class_names=dataset.target_names,\n",
        "                      filled=True, rounded=True,\n",
        "                      special_characters=True, precision=2)\n",
        "  graph = graphviz.Source( dot_data )\n",
        "  return graph\n",
        "\n",
        "print( \"Setup complete\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x61fU_BgXdSa",
        "colab_type": "text"
      },
      "source": [
        "## Train classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5wfFSmlXhuS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data, test_data, train_target, test_target, classifier = train_DecisionTreeClassifier( iris_dataset )\n",
        "print( \"Iris DecisionTreeClassifier trained\" )\n",
        "\n",
        "# train_data, test_data, train_target, test_target, classifier = train_DecisionTreeClassifier( pima_diabetes_dataset )\n",
        "# print( \"Pima Indian Diabetes DecisionTreeClassifier trained\" )\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7i_gI1KUXs2k",
        "colab_type": "text"
      },
      "source": [
        "## Predict label for new observation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3L4tzHvX12L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict label for new observation\n",
        "prediction = classifier.predict( test_data )\n",
        "print( \"test_target:\", test_target )\n",
        "print( \"prediction: \", prediction )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdT6LY8GX4YS",
        "colab_type": "text"
      },
      "source": [
        "## Visualize decision tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6TXUef8X8hA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualize decision tree\n",
        "visualize_decision_tree( classifier, iris_dataset )\n",
        "# visualize_decision_tree( classifier, pima_diabetes_dataset )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTKMHY8QbXjU",
        "colab_type": "text"
      },
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLit0xb0cEMa",
        "colab_type": "text"
      },
      "source": [
        "Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75oLeGrDcFcn",
        "colab_type": "code",
        "outputId": "19429774-8eac-4d95-e927-227fabf7a88f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import  matplotlib.pyplot  as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn  import preprocessing\n",
        "\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "from  tensorflow.keras  import Model\n",
        "from  tensorflow.keras  import Sequential\n",
        "from  tensorflow.keras.layers  import Dense\n",
        "from  tensorflow.keras.layers  import Dropout\n",
        "\n",
        "# items:[0,0,1], expected:2\n",
        "def get_class(items):\n",
        "  # print( \"items:\", items )\n",
        "  for i in range( 0, len( items ) ):\n",
        "    if ( items[i] == 1 ):\n",
        "      found_class = i\n",
        "  return found_class\n",
        "\n",
        "# Chart training progress\n",
        "def plot_training_progress(history):\n",
        "  accuracy     = history.history[     'accuracy' ]\n",
        "  val_accuracy = history.history[ 'val_accuracy' ]\n",
        "  loss     = history.history[     'loss' ]\n",
        "  val_loss = history.history[ 'val_loss' ]\n",
        "  epochs = range( len( accuracy ) )\n",
        "\n",
        "  plt.title( 'Training & Validation Accuracy' )\n",
        "  plt.plot( epochs,     accuracy, color='green',   label='Training' )\n",
        "  plt.plot( epochs, val_accuracy, color='orange', label='Validation' )\n",
        "  plt.xlabel( 'Epoch' )\n",
        "  plt.ylabel( 'Accuracy' )\n",
        "  plt.legend()\n",
        "  _ = plt.figure()\n",
        "\n",
        "  plt.title( 'Training & Validation Loss' )\n",
        "  plt.plot( epochs,     loss, color='red', label='Loss' )\n",
        "  plt.plot( epochs, val_loss, color='orange', label='Validation' )\n",
        "  plt.xlabel( 'Epoch' )\n",
        "  plt.ylabel( 'Loss' )\n",
        "  plt.legend()\n",
        "  _ = plt.figure()\n",
        "\n",
        "print( \"Neural Network Setup complete\" )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Neural Network Setup complete\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhRdnXoKbm3E",
        "colab_type": "text"
      },
      "source": [
        "### Build & Train Iris Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vPOuvqIj269",
        "colab_type": "text"
      },
      "source": [
        "**Build Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-MfAaYabxNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "outputId": "f7ee25d4-0f35-472b-dd45-0606857c67cb"
      },
      "source": [
        "X = preprocessing.scale( iris_dataset.data )\n",
        "y = to_categorical( iris_dataset.target )\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size=0.25, random_state=42\n",
        ")\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "     Dense( 10, input_dim=4, activation='relu' )\n",
        "     , Dense( 3, activation='softmax' )\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam'\n",
        "    , loss = 'categorical_crossentropy'\n",
        "    , metrics = [ 'accuracy' ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "plot = tf.keras.utils.plot_model( model, 'skip_connection.png', show_shapes=True )\n",
        "\n",
        "log_dir=\"logs/fit/\" + datetime.datetime.now().strftime( \"%Y%m%d-%H%M%S\" )\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard( log_dir=log_dir )\n",
        "\n",
        "plot\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 10)                50        \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 33        \n",
            "=================================================================\n",
            "Total params: 83\n",
            "Trainable params: 83\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEnCAYAAABWu9M0AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE\nQVR4nO3de1RTV9o/8O+BCEmQqwIiSOWiWBEvHe0IgpehMhVGUFFB68zQLjuKzgCt9ecLVEUU1NpB\nFlXGZUvtvPUCCC7QKu28WlFp1dpRxGJVoMVLGQEFuQa5ZP/+4E3exkAgkBByeD5r5Y/u7Jz9nNPk\n8bDPPs/hGGMMhBBCeMFA1wEQQgjRHErqhBDCI5TUCSGERyipE0IIjwhebLh8+TKSkpJ0EQshhBA1\neHp64t1331VoUzpTf/jwIbKysgYsKEL46sqVK7hy5Yquw9Arjx49ovzTS1euXMHly5eV2pXO1GWO\nHz+u1YAI4btly5YBoN+SOjIzMxESEkLHrBdk368X0Zw6IYTwCCV1QgjhEUrqhBDCI5TUCSGERyip\nE0IIj1BSJ2SQO3PmDMzNzXHq1CldhzIorV27FhzHyV+rVq1S6nP27FlER0dDKpVi8eLFcHR0hFAo\nhL29PYKCglBUVNTvOFpaWjBhwgS8//778raTJ09i9+7d6OjoUOibk5OjEPPIkSP7Pb4MJXVCBjkq\npNozKysr5OXl4e7du0hLS1N4b+vWrUhJSUFMTAykUikuXbqEo0ePoqamBgUFBZBIJJg9ezYqKir6\nFUNsbCzu3r2r0BYYGAihUAhfX188e/ZM3h4UFIRHjx7h4sWL8Pf379e4L6KkTsggFxAQgLq6Oixc\nuFDXoUAikcDLy0vXYSgRiUR4/fXXMX78eBgbG8vbd+3ahfT0dGRmZsLU1BRA512Y3t7eEIvFcHJy\nQkJCAurq6vDZZ5/1efxvv/0WP/zwQ5fvRUZGYsqUKfD390d7ezsAgOM42Nvbw8fHB+PGjevzuF2h\npE4I6bW0tDRUVVXpOoxeKS0txebNm7Ft2zYIhUIAgEAgUJrGcnZ2BgCUlZX1aRyJRIKNGzciOTm5\n2z5xcXEoLCxU2UdTKKkTMogVFBTA0dERHMdh3759AIDU1FSYmJhALBYjNzcXCxYsgJmZGRwcHHDs\n2DH5Z1NSUiAUCmFjY4O1a9fCzs4OQqEQXl5euHr1qrxfREQEjIyMMGrUKHnb+vXrYWJiAo7j8OTJ\nEwBAVFQUNmzYgLKyMnAcB1dXVwDAl19+CTMzMyQkJAzEIem1lJQUMMYQGBiosp9EIgEAmJmZ9Wmc\n2NhYrF+/HtbW1t32sbS0xJw5c5CcnKz16TRK6oQMYt7e3vj2228V2tatW4d33nkHEokEpqamyMjI\nQFlZGZydnfH222+jra0NQGeyDgsLQ3NzMyIjI1FeXo7r16+jvb0d8+fPx8OHDwF0Jr/ly5crjLF/\n/35s27ZNoS05ORkLFy6Ei4sLGGMoLS0FAPlFQKlUqpVj0FenT5+Gm5sbxGKxyn7fffcdgM5jra5v\nvvkGZWVlWLlyZY99p02bhl9++QU3b95Uexx1UFInRI95eXnBzMwM1tbWCA0NRVNTEx48eKDQRyAQ\n4OWXX4axsTEmTpyI1NRUNDQ04NChQxqJISAgAPX19di8ebNGtqcJTU1N+Pnnn+Hi4tJtn8rKSqSn\npyMyMhKenp49ntG/SCKRICoqCqmpqb3qL5s7v3XrllrjqKvbgl6EEP1iZGQEAPIz9e5Mnz4dYrEY\nd+7cGYiwdKKqqgqMMZVn6Z6enmhqasLy5cuxY8cODBs2TK0xYmJi8Je//AX29va96i+LpbKyUq1x\n1EVJnZAhyNjYGNXV1boOQ2taWloAQGElzItsbGyQlpYGd3d3tbdfUFCAW7duqfXsCZFIpBCbttD0\nCyFDTFtbG549ewYHBwddh6I1sgT64k0/v2ZtbQ0LC4s+bT8tLQ3nzp2DgYGB/AYi2YXShIQEcByH\n77//XuEzra2tCrFpCyV1QoaY/Px8MMYwc+ZMeZtAIOhx2kaf2NjYgOM41NXVddvn1KlTvZ46edGh\nQ4fAGFN4yf7yiY2NBWMM06dPV/iMLBZbW9s+jdlblNQJ4TmpVIra2lq0t7ejqKgIUVFRcHR0RFhY\nmLyPq6srampqkJOTg7a2NlRXV+P+/ftK27KyskJFRQXKy8vR0NCAtrY25OXlDboljWKxGM7Oznj0\n6FGX75eWlsLW1hYhISFK74WGhsLW1hbXr1/XaEyyWDw8PDS63RdRUidkENu3bx9mzJgBANi0aROC\ngoKQmpqKvXv3AgAmT56Mn376CR9//DE2bNgAAHj99ddRUlIi30ZLSws8PDwgEong4+OD8ePH4/z5\n8wrzzevWrcO8efOwYsUKuLm5Yfv27fJpAk9PT/nyx/DwcNjY2GDixInw9/dHTU3NgByHvggICEBx\ncbF8HfqvqVor3traiqqqKuTm5mo0nmvXrsHe3h6TJ0/W6HZfRBdKCRnE/vrXv+Kvf/2rUvu6desU\n/lu2Rr0rpqam3Z6xylhZWeHrr79Wav/ggw8U/nvatGkoLy9XaFuwYAHq6+tVbl8X/va3vyE1NRXZ\n2dlKRb7GjRvX7SqUrKwszJ07Fy+99JJa440cObLbfyyePn2Kc+fOYceOHeA4Tq3tqovO1AnhOVUX\nC/lCIpHgq6++QklJifyCpKurK+Lj4xEfH4/GxsZebaejowM5OTloaGhAaGioxuKLi4vD1KlTERER\nAaDzL4WKigoUFBTIb+LSFErqhBC9V1NTIy/o9dZbb8nbo6OjsWzZMoSGhqq8aCqTn5+P7Oxs5OXl\n9Xgnam8lJSWhsLAQZ86cka+Fz83NlRf0On36tEbGkdFKUl+9ejVMTU3BcRwKCwu1MYTW8aGG9ZUr\nV/Dyyy/Ll13Z2tpix44dug5LQXZ2NpydneXLwkaNGtVlPWyivpiYGBw6dAh1dXVwcnJCVlaWrkPS\nigMHDiisQjl8+LDC+wkJCYiIiMDOnTt73Javry+OHDmiUAenP3Jzc/H8+XPk5+fD0tJS3r5o0SKF\nmGX1dTRBK3Pqn3zyCV577TWsWLFCG5sfEHyoYT1z5kz8+OOPeP311/HVV1/h7t27fV6Xqy3BwcEI\nDg6Gq6srnjx5gsePH+s6JN5ITExEYmKirsMYFPz8/ODn5zfg4wYFBSEoKGhAx6Tpl25QDWvt4NO+\nEDIYaS2pa/sK71CiTzWse8KnfSFkMNJIUmeMYc+ePXBzc4OxsTHMzc2xceNGpX4dHR3YsmULHB0d\nIRKJMHnyZGRkZADofY1oALhw4QJeffVViMVimJmZwcPDQ76kStUYvcX3GtaDbV/UdenSJUycOBHm\n5uYQCoXw8PDAV199BaDzeo5sft7FxQU3btwAALz55psQi8UwNzfHyZMnAaj+rnzwwQcQi8UwNTVF\nVVUVNmzYAHt7e6XHlREy6LAXZGRksC6aVYqNjWUcx7G///3vrLa2ljU3N7P9+/czAOzGjRvyfu+9\n9x4zNjZmWVlZrLa2lsXExDADAwN27do1+XYAsHPnzrG6ujpWVVXFfHx8mImJCWttbWWMMdbY2MjM\nzMzY7t27mUQiYY8fP2ZLlixh1dXVvRqjtx4+fMgAsI8++khhP3uKjzHG1qxZw0xMTNjt27dZS0sL\nKy4uZjNmzGCmpqbswYMH8n5vvPEGs7W1VRh3z549DIB8fxhjLDg4mLm4uCj0++KLL5ipqSmLj4/v\ncV9+//vfMwCstrZ2UO4LY4y5uLgwc3PzHveFMcaOHz/O4uLiWE1NDXv69CmbOXMmGzFihMIYhoaG\n7JdfflH43MqVK9nJkyfl/93b72NkZCT76KOP2JIlS9iPP/7YqxgZY2zp0qVs6dKlve5P+pZ/hqru\nvl/9PlOXSCTYu3cvXnvtNbz77ruwsLCASCSClZWVQr+WlhakpqZi8eLFCA4OhoWFBd5//30MGzZM\nqa6zqhrR5eXlqK+vh7u7O4RCIWxtbZGdnY2RI0eqNUZ/8KmG9WDYF3UtXboUW7duhaWlJaysrBAY\nGIinT5/Ka2+Eh4ejo6NDIb76+npcu3ZN/pBfdb4ru3btwl//+ldkZ2djwoQJA7ejhPRBv1e/lJaW\norm5Gb6+vir73b17F83NzZg0aZK8TSQSYdSoUSrrOr9YI9rZ2Rk2NjZYtWoVIiMjERYWhrFjx/Zr\njP7gUw1rfd0X2dpf2U02v/vd7zB+/Hh8+umniImJAcdxSE9PR2hoKAwNDQEM3HclKyuLri/1AR2z\n3lm6dKlSW7+Tuuz2Y1XP5wM6n0QCAO+//z7ef/99hffs7Ox6PZ5IJMLXX3+N//qv/0JCQgLi4+Ox\nfPlyHDp0SGNjaAufaljrcl9Onz6NPXv2oLi4GPX19Ur/CHEch7Vr1+Ldd9/FuXPn8Nprr+G///u/\nceTIEXmfgfquzJw5E++8847Gtsd3ly9fRnJystrXwYYiWf2fF/U7qcue0v38+XOV/WRJf+/evYiK\niurXmO7u7jh16hSqq6uRlJSEXbt2wd3dXX5brybG0DQ+1bAe6H25ePEi/v3vf+Odd97BgwcPsHjx\nYixZsgSffvopRo8ejY8++gj/7//9P4XPhIWFISYmBp988gnGjBkDMzMzhVoemvw+quLg4KD0/E+i\nWnJyMh2zXjh+/HiX7f2eU580aRIMDAxw4cIFlf3GjBkDoVDY7ztMKyoqcPv2bQCdP8ydO3filVde\nwe3btzU2hjbwqYb1QO/Lv//9b5iYmADofL5jW1sb1q1bB2dnZwiFwi7/VLe0tERISAhycnLw4Ycf\nKhW7GszfFUL6o99J3draGsHBwcjKykJaWhrq6+tRVFSEgwcPKvQTCoV48803cezYMaSmpqK+vh4d\nHR149OgR/vOf//R6vIqKCqxduxZ37txBa2srbty4gfv372PmzJkaG0MT+FTDWtv70p22tjZUVlYi\nPz9fntQdHR0BAGfPnkVLSwtKSkoUllf+Wnh4OJ4/f44vvvhC6SaywfRdIUSjXlwO05clRQ0NDWz1\n6tVsxIgRbPjw4czb25tt2bKFAWAODg7s5s2bjDHGnj9/zjZt2sQcHR2ZQCBg1tbWLDg4mBUXF7P9\n+/czsVjMALBx48axsrIydvDgQWZmZsYAsJdeeondu3ePlZeXMy8vL2ZpackMDQ3Z6NGjWWxsLGtv\nb+9xjN766KOP2KhRoxgAJhaLWWBgYK/jY6xzGeCwYcOYvb09EwgEzMzMjC1atIiVlZUpjPP06VM2\nb948JhQKmZOTE/vb3/7GNm7cyAAwV1dX+ZLB69evs5deeomJRCLm7e3NHj9+zM6cOcNMTU3Zjh07\nut2PK1euMHd3d2ZgYMAAsFGjRrGEhIRBtS//+Mc/mIuLCwOg8nXixAn5WJs2bWJWVlbMwsKCLVu2\njO3bt48BYC4uLgrLLBljbNq0aSw6OrrL46Pqu7J7924mEokYADZmzBj2+eef9+aro4CWNKqPljT2\nXnffL44xxSInmZmZCAkJ4UXtE11Zu3Ytjh8/jqdPn+o6lH7T930JCAjAvn374OTkNOBjL1u2DED3\nc59EGeWf3uvu+0W1X7SETzWs9Wlffj2dU1RUBKFQqJOEToiuDJmkfufOHfnt46pemiyMTwbepk2b\nUFJSgnv37uHNN9/E9u3bdR0S0bK1a9cq/Ia7Kt189uxZREdHQyqVYvHixXB0dIRQKIS9vT2CgoJQ\nVFTU7zhaWlowYcIEhSWyJ0+exO7du5VOjHJychRiHjlyZL/HlxkySX3ChAlKT//u6pWent6vcfhU\nw1of90UsFmPChAl47bXXEBcXh4kTJ+o6JDIArKyskJeXh7t37yItLU3hva1btyIlJQUxMTGQSqW4\ndOkSjh49ipqaGhQUFEAikWD27NmoqKjoVwyxsbFKtYECAwMhFArh6+uLZ8+eyduDgoLw6NEjXLx4\nUX6Xs6YMmaQ+UBITE/H8+XMwxvDzzz93eceXvtDHfdmxYwc6Ojrw4MGDQVE2WdcGotTxYCinLBKJ\n5E8++vUDtXft2oX09HRkZmbC1NQUQOeDtL29vSEWi+Hk5ISEhATU1dXhs88+6/P43377LX744Ycu\n34uMjMSUKVPg7++P9vZ2AJ03yMmefDRu3Lg+j9sVSuqE8NhAlDoerOWUS0tLsXnzZmzbtk1+k6RA\nIFB6mpmzszMAoKysrE/jSCQSbNy4EcnJyd32iYuLQ2Fhoco+mkJJnZBBhDGGpKQkeQE1S0tLLFq0\nSKEeTX9KHetDaWhNSUlJAWMMgYGBKvtJJBIAgJmZWZ/GiY2Nxfr161WWSrG0tMScOXOQnJys9ZU9\nlNQJGUTi4uIQHR2N2NhYVFVV4eLFi3j48CF8fHxQWVkJoDNZvXgb/f79+7Ft2zaFtuTkZCxcuBAu\nLi5gjKG0tBQREREICwtDc3MzIiMjUV5ejuvXr6O9vR3z58/Hw4cP+z0G8H8rpqRSqeYOjppOnz4N\nNze3Hh8g/d133wEAvL291R7jm2++QVlZGVauXNlj32nTpuGXX37BzZs31R5HHZTUCRkkJBIJkpKS\nsGTJEqxatQrm5ubw8PDAgQMH8OTJE6W7tPtDX0pD91VTUxN+/vlnuLi4dNunsrIS6enpiIyMhKen\nZ49n9C+SSCSIiopCampqr/rL5s5v3bql1jjq0sqDpwkh6isuLkZjYyOmT5+u0D5jxgwYGRl1Ww5B\nEwZbOeX+qqqqAmNM5Vm6p6cnmpqasHz5cuzYsUNewrm3YmJi8Je//AX29va96i+LRfYXl7ZQUidk\nkJAteRs+fLjSexYWFmhoaNDq+HwqDd3S0gIACithXmRjY4O0tDS4u7urvf2CggLcunULSUlJvf6M\nSCRSiE1baPqFkEHCwsICALpM3toudcyn0tDA/yVQVXdDW1tby4+5utLS0nDu3DkYGBjIbyCSXShN\nSEgAx3H4/vvvFT7T2tqqEJu2UFInZJCYNGkShg8frpQMrl69itbWVvzmN7+Rt2m61DGfSkMDnWfh\nHMehrq6u2z6nTp3q9dTJiw4dOqR046Lsr5zY2FgwxpSm0WSx2Nra9mnM3qKkTsggIRQKsWHDBpw4\ncQKHDx9GfX09bt26hfDwcNjZ2WHNmjXyvv0tdcyn0tBdEYvFcHZ2lj+Z7UWlpaWwtbVFSEiI0nuh\noaGwtbXF9evXNRqTLBYPDw+NbvdFlNQJGUS2bt2KxMRExMfHY+TIkZgzZw7Gjh2rUFMeANatW4d5\n8+ZhxYoVcHNzw/bt2+V/1nt6esqXJoaHh8PGxgYTJ06Ev78/ampqAHTO63p4eEAkEsHHxwfjx4/H\n+fPnFeag+zuGrgUEBKC4uFi+Dv3XVK0Vb21tRVVVFXJzczUaz7Vr12Bvb4/JkydrdLsvogulhAwi\nHMfhvffew3vvvaeyn5WVFb7++mul9g8++EDhv6dNm4by8nKlfqampt2exWpijAULFqC+vl7l9rXt\nb3/7G1JTU5Gdna1U5GvcuHHdrkLJysrC3LlzFR5/2BsjR47s9h+Lp0+f4ty5c9ixY4fWH6pNZ+qE\nDEH6VE65NyQSCb766iuUlJTIL0i6uroiPj4e8fHxaGxs7NV2Ojo6kJOTg4aGBo1WbI2Li8PUqVMR\nEREBoPMvhYqKChQUFMhv2NIUSuqEEL1XU1MjL+j11ltvydujo6OxbNkyhIaGqrxoKpOfn4/s7Gzk\n5eX1eCdqbyUlJaGwsBBnzpyRr4XPzc2VF/Q6ffq0RsaRoaROyBCij+WUe3LgwAGFVSiHDx9WeD8h\nIQERERHYuXNnj9vy9fXFkSNHFGre9Edubi6eP3+O/Px8WFpaytsXLVqkELOslo4m0Jw6IUNIYmIi\nEhMTdR3GgPPz84Ofn9+AjxsUFISgoKABHZPO1AkhhEcoqRNCCI9QUieEEB6hpE4IITzS7YXSzMzM\ngYyDEN6R3dxDv6Xeu3z5MgA6Zr3x6NGjrguwsRdkZGQwAPSiF73oRa9B/lq6dOmLKZxxTNsPzCNk\nEOA4DhkZGUqPaCOEb2hOnRBCeISSOiGE8AgldUII4RFK6oQQwiOU1AkhhEcoqRNCCI9QUieEEB6h\npE4IITxCSZ0QQniEkjohhPAIJXVCCOERSuqEEMIjlNQJIYRHKKkTQgiPUFInhBAeoaROCCE8Qkmd\nEEJ4hJI6IYTwCCV1QgjhEUrqhBDCI5TUCSGERyipE0IIj1BSJ4QQHqGkTgghPEJJnRBCeISSOiGE\n8AgldUII4RFK6oQQwiOU1AkhhEcoqRNCCI9QUieEEB6hpE4IITxCSZ0QQniEY4wxXQdBiCatWbMG\nd+/eVWi7fv06nJycYGlpKW8zNDTEP//5Tzg4OAx0iIRojUDXARCiaba2tjh48KBSe1FRkcJ/Ozs7\nU0InvEPTL4R3Vq5c2WMfIyMjhIWFaT8YQgYYTb8QXpo0aRJu374NVV/vu3fvYvz48QMYFSHaR2fq\nhJf+9Kc/wdDQsMv3OI7DlClTKKETXqKkTnhpxYoV6Ojo6PI9Q0ND/PnPfx7giAgZGDT9QnjLy8sL\nV69ehVQqVWjnOA4PHz6Evb29jiIjRHvoTJ3w1h//+EdwHKfQZmBgAG9vb0rohLcoqRPeWrZsmVIb\nx3H405/+pINoCBkYlNQJb40cORK+vr4KF0w5jsPixYt1GBUh2kVJnfDaqlWr5MsaDQ0N8fvf/x4j\nRozQcVSEaA8ldcJrS5YsgZGREQCAMYZVq1bpOCJCtIuSOuE1ExMT/OEPfwDQeRfpwoULdRwRIdpF\nSZ3w3htvvAEAWLx4MUxMTHQcDSHaxZt16i8uXSOEEHVkZGRg+fLlug6j33hVpTEqKgqenp66DoNo\n0eXLl5GcnIyMjAy1Pnf48GGEhoZCIODVV77XQkJC6PehQkhIiK5D0Bhenanz5V9a0r3MzEyEhISo\nLNTVlZaWFgiFQi1FNfjR70M1Ph0fmlMnQ8JQTuhkaKGkTgghPEJJnRBCeISSOiGE8AgldUII4RFK\n6mRIOnPmDMzNzXHq1Cldh6KXzp49i+joaEilUixevBiOjo4QCoWwt7dHUFCQ0kO++6KlpQUTJkzA\n+++/L287efIkdu/e3e0DUAgldTJE8WQlr05s3boVKSkpiImJgVQqxaVLl3D06FHU1NSgoKAAEokE\ns2fPRkVFRb/GiY2Nxd27dxXaAgMDIRQK4evri2fPnvVr+3xFSZ0MSQEBAairqxsUtWAkEgm8vLx0\nHUav7Nq1C+np6cjMzISpqSkAwNPTE97e3hCLxXByckJCQgLq6urw2Wef9Xmcb7/9Fj/88EOX70VG\nRmLKlCnw9/dHe3t7n8fgK0rqhOhYWloaqqqqdB1Gj0pLS7F582Zs27ZNvu5fIBAoTWE5OzsDAMrK\nyvo0jkQiwcaNG5GcnNxtn7i4OBQWFqrsM1RRUidDTkFBARwdHcFxHPbt2wcASE1NhYmJCcRiMXJz\nc7FgwQKYmZnBwcEBx44dk382JSUFQqEQNjY2WLt2Lezs7CAUCuXPQ5WJiIiAkZERRo0aJW9bv349\nTExMwHEcnjx5AqCztMWGDRtQVlYGjuPg6uoKAPjyyy9hZmaGhISEgTgkvZKSkgLGGAIDA1X2k0gk\nAAAzM7M+jRMbG4v169fD2tq62z6WlpaYM2cOkpOTaSrtBZTUyZDj7e2Nb7/9VqFt3bp1eOeddyCR\nSGBqaoqMjAyUlZXB2dkZb7/9Ntra2gB0JuuwsDA0NzcjMjIS5eXluH79Otrb2zF//nw8fPgQQGcC\nfPGW8/3792Pbtm0KbcnJyVi4cCFcXFzAGENpaSkAyC8EvvjQbF06ffo03NzcIBaLVfb77rvvAHQe\nZ3V98803KCsrw8qVK3vsO23aNPzyyy+4efOm2uPwGSV1Ql7g5eUFMzMzWFtbIzQ0FE1NTXjw4IFC\nH4FAgJdffhnGxsaYOHEiUlNT0dDQgEOHDmkkhoCAANTX12Pz5s0a2V5/NTU14eeff4aLi0u3fSor\nK5Geno7IyEh4enr2eEb/IolEgqioKKSmpvaq/7hx4wAAt27dUmscvhuaJesI6SXZU5NkZ+rdmT59\nOsRiMe7cuTMQYQ24qqoqMMZUnqV7enqiqakJy5cvx44dOzBs2DC1xoiJicFf/vIX2Nvb96q/LJbK\nykq1xuE7SuqEaIixsTGqq6t1HYZWtLS0AOjcx+7Y2NggLS0N7u7uam+/oKAAt27dQlJSUq8/IxKJ\nFGIjnWj6hRANaGtrw7Nnz+Dg4KDrULRClkBV3fRjbW0NCwuLPm0/LS0N586dg4GBATiOA8dx8gul\nCQkJ4DgO33//vcJnWltbFWIjnSipE6IB+fn5YIxh5syZ8jaBQNDjtI2+sLGxAcdxqKur67bPqVOn\nej118qJDhw6BMabwkv3VExsbC8YYpk+frvAZWSy2trZ9GpOvKKkT0gdSqRS1tbVob29HUVERoqKi\n4OjoiLCwMHkfV1dX1NTUICcnB21tbaiursb9+/eVtmVlZYWKigqUl5ejoaEBbW1tyMvLG1RLGsVi\nMZydnfHo0aMu3y8tLYWtrW2XTxAKDQ2Fra0trl+/rtGYZLF4eHhodLv6jpI6GXL27duHGTNmAAA2\nbdqEoKAgpKamYu/evQCAyZMn46effsLHH3+MDRs2AABef/11lJSUyLfR0tICDw8PiEQi+Pj4YPz4\n8Th//rzCnPO6deswb948rFixAm5ubti+fbt8qsDT01O+/DE8PBw2NjaYOHEi/P39UVNTMyDHQV0B\nAQEoLi6Wr0P/NVVrxVtbW1FVVYXc3FyNxnPt2jXY29tj8uTJGt2u3mM8AYBlZGToOgyiZRkZGUzX\nX9s1a9YwKysrncagLk38PkpKSphAIGCff/65Wp/r6OhgPj4+LC0trV/j/9qTJ0+YUChkH374oUa2\nx6f8QWfqhPTBUKwS6Orqivj4eMTHx6OxsbFXn+no6EBOTg4aGhoQGhqqsVji4uIwdepUREREaGyb\nfEFJ/X+tXr0apqam4DgOhYWFug5HbdnZ2XB2dpavHJC9jIyMYGNjg7lz52LPnj2ora3VdahEj0VH\nR2PZsmUIDQ1VedFUJj8/H9nZ2cjLy+vxTtTeSkpKQmFhIc6cOaP2WvihgCIyWF8AACAASURBVJL6\n//rkk0/w8ccf6zqMPgsODsZPP/0EFxcXmJubgzEGqVSKqqoqZGZmwsnJCZs2bYK7u7vS0jDSezEx\nMTh06BDq6urg5OSErKwsXYc04BISEhAREYGdO3f22NfX1xdHjhxRqIHTH7m5uXj+/Dny8/NhaWmp\nkW3yDd18xGMcx8HCwgJz587F3LlzERAQgJCQEAQEBODevXswNzfXdYh6JzExEYmJiboOQ+f8/Pzg\n5+c34OMGBQUhKChowMfVJ3Sm/iscx+k6BK1aunQpwsLCUFVVhQMHDug6HEKIFgzZpM4Yw549e+Dm\n5gZjY2OYm5tj48aNSv06OjqwZcsWODo6QiQSYfLkycjIyADQ+3KtAHDhwgW8+uqrEIvFMDMzg4eH\nB+rr63scA9BsGVbZOuq8vLxBtY+EEA3R9fIbTYGaS5JiY2MZx3Hs73//O6utrWXNzc1s//79DAC7\nceOGvN97773HjI2NWVZWFqutrWUxMTHMwMCAXbt2Tb4dAOzcuXOsrq6OVVVVMR8fH2ZiYsJaW1sZ\nY4w1NjYyMzMztnv3biaRSNjjx4/ZkiVLWHV1da/G+OKLL5ipqSmLj4/vcb9cXFyYubl5t+/X19cz\nAGzMmDGDah97azAsadRH6v4+hho+HR/e/DrU+Z/S3NzMxGIxmz9/vkL7sWPHFJK6RCJhYrGYhYaG\nKnzW2NiYrVu3jjH2fwlPIpHI+8j+cSgtLWWMMfbDDz8wAOyLL75QiqU3Y6ijp6TOGGMcxzELCwu9\n3EdK6n3Dp6SlDXw6PkPyQmlpaSmam5vh6+urst/du3fR3NyMSZMmydtEIhFGjRqlssTqi+VanZ2d\nYWNjg1WrViEyMhJhYWEYO3Zsv8boq6amJjDG5E+l0dd9zMzM7NPnhrLLly/rOgQyEHT9r4qmQI1/\nac+cOcMAKN3h9uKZ+jfffMMAdPmaOXMmY6zrs9iPP/6YAWA//vijvO2HH35gf/jDH5hAIGAcx7GQ\nkBDW3NzcqzHU0dOZ+vXr1xkA5ufnp5f7KDtTpxe9NP3iy5n6kLxQKnto7vPnz1X2k5X+3Lt3r1IF\nOXXPetzd3XHq1ClUVFRg06ZNyMjIwIcffqjRMXrjyy+/BAAsWLAAgP7u44vboZfqFwBkZGToPI7B\n+uKTIZnUJ02aBAMDA1y4cEFlvzFjxkAoFPb7DtOKigrcvn0bQGcS3blzJ1555RXcvn1bY2P0xuPH\nj7F37144ODjgrbfeAsC/fSRkqBuSSd3a2hrBwcHIyspCWloa6uvrUVRUhIMHDyr0EwqFePPNN3Hs\n2DGkpqaivr4eHR0dePToEf7zn//0eryKigqsXbsWd+7cQWtrK27cuIH79+9j5syZvRpD3TKsjDE0\nNjZCKpWCsc661BkZGZg1axYMDQ2Rk5Mjn1MfLPtICNEQxhNQc06soaGBrV69mo0YMYINHz6ceXt7\nsy1btjAAzMHBgd28eZMxxtjz58/Zpk2bmKOjIxMIBMza2poFBwez4uJitn//fiYWixkANm7cOFZW\nVsYOHjzIzMzMGAD20ksvsXv37rHy8nLm5eXFLC0tmaGhIRs9ejSLjY1l7e3tPY7BWOc1AFNTU7Zj\nx45u9+fkyZNs8uTJTCwWMyMjI2ZgYMAAyFe6vPrqqyw+Pp49ffpU6bODYR97i1a/9I26v4+hhk/H\nh2OMHxNKHMchIyMDy5cv13UoRIsyMzMREhLCu3lQbaPfh2p8Oj5DcvqFEEL4ipI6IYTwCCV1QohK\nZ8+eRXR0NKRSKRYvXgxHR0cIhULY29sjKCgIRUVFfd62VCrF3r174eXl1W2fgoICzJo1C2KxGHZ2\ndti0aZPCcuSTJ09i9+7dQ/LBJV2hpE4I6dbWrVuRkpKCmJgYSKVSXLp0CUePHkVNTQ0KCgogkUgw\ne/ZsVFRUqL3tkpISzJ49G++++y6am5u77FNcXAw/Pz/4+vqiuroaJ06cwKefforw8HB5n8DAQAiF\nQvj6+uLZs2d93le+oKROiJokEonKM0t9GaMnu3btQnp6OjIzM2Fqagqg84HZ3t7eEIvFcHJyQkJC\nAurq6vDZZ5+pte2bN2/iv/7rvxAeHo6pU6d222/79u0YNWoUtm3bBhMTE3h6emLTpk347LPPFEpM\nREZGYsqUKfD390d7e3uf9pcvKKkToqa0tDRUVVXp/RiqlJaWYvPmzdi2bZv8DmyBQIBTp04p9HN2\ndgYAlJWVqbX9KVOmIDs7G2+88QaMjY277NPe3o7Tp09jzpw5Cs86WLBgARhjyM3NVegfFxeHwsJC\nJCcnqxUL31BSJ7zHGENSUhJefvllGBsbw9LSEosWLVI404uIiICRkZHCY9fWr18PExMTcByHJ0+e\nAACioqKwYcMGlJWVgeM4uLq6IiUlBUKhEDY2Nli7di3s7OwgFArh5eWFq1evamQMQLN19XuSkpIC\nxhgCAwNV9pNIJAAgv5lNk3766Sc0NjbC0dFRod3FxQUAlObyLS0tMWfOHCQnJw/pJa+U1AnvxcXF\nITo6GrGxsaiqqsLFixfx8OFD+Pj4oLKyEkBnEntxjfL+/fuxbds2hbbk5GQsXLgQLi4uYIyhtLQU\nERERCAsLQ3NzMyIjI1FeXo7r16+jvb0d8+fPx8OHD/s9BgD5hUCpVKq5g9ON06dPw83NrceHRX/3\n3XcAAG9vb43H8PjxYwCQT/3ICIVCiEQi+f+7X5s2bRp++eUX3Lx5U+Px6AtK6oTXJBIJkpKSsGTJ\nEqxatQrm5ubw8PDAgQMH8OTJE6XSEP0hEAjkfw1MnDgRqampaGhowKFDhzSy/YCAANTX12Pz5s0a\n2V53mpqa8PPPP8vPiLtSWVmJ9PR0REZGwtPTs8cz+r6QrXAxNDRUem/YsGHyvxJ+bdy4cQCAW7du\naTwefTEk66mToaO4uBiNjY2YPn26QvuMGTNgZGSkMD2iadOnT4dYLNZKXXxtqqqqAmNM5Vm6p6cn\nmpqasHz5cuzYsQPDhg3TeByyufyuLny2trZCJBIptcti7uosfqigpE54TbbEbfjw4UrvWVhYoKGh\nQavjGxsbo7q6WqtjaFpLSwsAdHsBEwBsbGyQlpYGd3d3rcUhu/Yge86tTHNzM1paWmBnZ6f0GVmi\nl+3DUETTL4TXLCwsAKDL5P3s2TM4ODhobey2tjatj6ENssSo6mYea2tr+bHVFicnJ5iamuL+/fsK\n7bJrDJMnT1b6TGtrKwB0eRY/VNCZOuG1SZMmYfjw4fj+++8V2q9evYrW1lb85je/kbcJBAL54/k0\nIT8/H4wxzJw5U2tjaIONjQ04jkNdXV23fV5c2qgNAoEA/v7+uHjxIqRSKQwMOs9B8/LywHFcl/P4\nsphtbW21Ht9gRWfqhNeEQiE2bNiAEydO4PDhw6ivr8etW7cQHh4OOzs7rFmzRt7X1dUVNTU1yMnJ\nQVtbG6qrq5XOEgHAysoKFRUVKC8vR0NDgzxJS6VS1NbWor29HUVFRYiKioKjoyPCwsI0Moa6dfX7\nSiwWw9nZGY8ePery/dLSUtja2iIkJETpvdDQUNja2uL69esaiWXz5s2orKzE1q1b0dTUhMuXL2PP\nnj0ICwuDm5ubUn9ZzB4eHhoZXx9RUie8t3XrViQmJiI+Ph4jR47EnDlzMHbsWOTn58PExETeb926\ndZg3bx5WrFgBNzc3bN++Xf5nvKenp3xpYnh4OGxsbDBx4kT4+/ujpqYGQOc8roeHB0QiEXx8fDB+\n/HicP39eYW66v2MMlICAABQXF3e5wkTVGvDW1lZUVVUp3Rj0oitXrsDb2xujR4/G1atXcfPmTdjZ\n2WHWrFm4ePGivJ+7uzu++uor/Otf/8KIESMQHByMt956C//4xz+63O61a9dgb2/f5dTMkKGbMu6a\nBx4VuSfdG6wPyVizZg2zsrLSdRjdUvf3UVJSwgQCAfv888/VGqejo4P5+PgoPdR9IDx58oQJhUL2\n4Ycfqv1ZPuUPOlMnREP4VCXQ1dUV8fHxiI+PR2NjY68+09HRgZycHDQ0NCA0NFTLESqLi4vD1KlT\nERERMeBjDyaU1AkhXYqOjsayZcsQGhqq8qKpTH5+PrKzs5GXl9fjnaialpSUhMLCQpw5c0Yra+b1\nCSV1QvopJiYGhw4dQl1dHZycnJCVlaXrkDQmISEBERER2LlzZ499fX19ceTIEYXaNgMhNzcXz58/\nR35+PiwtLQd07MGIljQS0k+JiYlITEzUdRha4+fnBz8/P12H0a2goCAEBQXpOoxBg87UCSGERyip\nE0IIj1BSJ4QQHqGkTgghPMKrC6V79+7F8ePHdR0G0SLZbeDLli3TcST6h34fQwPHGD+e+0Q/cqJK\nXl4epk2bNuDL7Yj+ePfdd+Hp6anrMPqNN0mdEFU4jkNGRobS4+QI4RuaUyeEEB6hpE4IITxCSZ0Q\nQniEkjohhPAIJXVCCOERSuqEEMIjlNQJIYRHKKkTQgiPUFInhBAeoaROCCE8QkmdEEJ4hJI6IYTw\nCCV1QgjhEUrqhBDCI5TUCSGERyipE0IIj1BSJ4QQHqGkTgghPEJJnRBCeISSOiGE8AgldUII4RFK\n6oQQwiOU1AkhhEcoqRNCCI9QUieEEB6hpE4IITxCSZ0QQniEkjohhPAIJXVCCOERSuqEEMIjlNQJ\nIYRHKKkTQgiPCHQdACGa9uzZMzDGlNqbmppQW1ur0DZ8+HAMGzZsoEIjROs41tW3nxA99rvf/Q7n\nz5/vsZ+hoSF++eUX2NraDkBUhAwMmn4hvLNixQpwHKeyj4GBAWbPnk0JnfAOJXXCO0uXLoVAoHpm\nkeM4/OlPfxqgiAgZOJTUCe9YWlrCz88PhoaG3fYxMDDA4sWLBzAqQgYGJXXCS6tWrYJUKu3yPYFA\ngICAAJibmw9wVIRoHyV1wkuBgYEwNjbu8r2Ojg6sWrVqgCMiZGBQUie8JBaLsXjx4i6XK4pEIvj7\n++sgKkK0j5I64a2VK1eira1NoW3YsGFYunQpRCKRjqIiRLsoqRPe+v3vf680b97W1oaVK1fqKCJC\ntI+SOuGtYcOGITQ0FEZGRvI2CwsL+Pr66jAqQrSLkjrhtRUrVqC1tRVAZ5JftWpVj2vYCdFnVCaA\n8JpUKsXo0aNRWVkJACgoKMCsWbN0HBUh2kNn6oTXDAwM8Mc//hEAYGdnBy8vLx1HRIh2Dfq/QzMz\nM3UdAtFzI0eOBAD89re/xfHjx3UcDdF3Xl5ecHBw0HUY3Rr00y89FWYihJCBlJGRgeXLl+s6jG7p\nxfRLRkYGGGP0olevXxkZGQAg/+/jx4/rPCZ9eNHvrefjM9jpRVInpL+WLl2q6xAIGRCU1AkhhEco\nqRNCCI9QUieEEB6hpE4IITxCSZ0QQniEkjohKpw5cwbm5uY4deqUrkMZ9M6ePYvo6GhIpVIsXrwY\njo6OEAqFsLe3R1BQEIqKivq8balUir1796q8I1hWAkIsFsPOzg6bNm3C8+fP5e+fPHkSu3fvRkdH\nR5/j0AeU1AlRQV/WJuva1q1bkZKSgpiYGEilUly6dAlHjx5FTU0NCgoKIJFIMHv2bFRUVKi97ZKS\nEsyePRvvvvsumpubu+xTXFwMPz8/+Pr6orq6GidOnMCnn36K8PBweZ/AwEAIhUL4+vri2bNnfd7X\nQY8NcgBYRkaGrsMgeiYjI4PpwddbLc3NzczT01OrY/Tl97Zz5042fvx4JpFIGGOMtbW1sT/84Q8K\nfb777jsGgCUkJKi17cLCQrZkyRJ2+PBhNnXqVDZlypQu+4WEhDAnJycmlUrlbXv27GEcx7Eff/xR\noW9ERATz9PRkbW1tasXCmH7kIzpTJ0RPpKWloaqqStdhKCgtLcXmzZuxbds2CIVCAJ0P9n5xusrZ\n2RkAUFZWptb2p0yZguzsbLzxxhvdPnO2vb0dp0+fxpw5cxTKiixYsACMMeTm5ir0j4uLQ2FhIZKT\nk9WKRV9QUiekGwUFBXB0dATHcdi3bx8AIDU1FSYmJhCLxcjNzcWCBQtgZmYGBwcHHDt2TP7ZlJQU\nCIVC2NjYYO3atbCzs4NQKISXlxeuXr0q7xcREQEjIyOMGjVK3rZ+/XqYmJiA4zg8efIEABAVFYUN\nGzagrKwMHMfB1dUVAPDll1/CzMwMCQkJA3FIlKSkpIAxhsDAQJX9JBIJAMDMzEzjMfz0009obGyE\no6OjQruLiwsAKM3lW1paYs6cOUhOTubl9BoldUK64e3tjW+//Vahbd26dXjnnXcgkUhgamqKjIwM\nlJWVwdnZGW+//bb8magREREICwtDc3MzIiMjUV5ejuvXr6O9vR3z58/Hw4cPAXQmxReLQ+3fvx/b\ntm1TaEtOTsbChQvh4uICxhhKS0sBQH7RTyqVauUY9OT06dNwc3ODWCxW2e+7774D0HlMNe3x48cA\nAFNTU4V2oVAIkUgkr6X/a9OmTcMvv/yCmzdvajweXaOkTkgfeXl5wczMDNbW1ggNDUVTUxMePHig\n0EcgEODll1+GsbExJk6ciNTUVDQ0NODQoUMaiSEgIAD19fXYvHmzRranjqamJvz888/yM+KuVFZW\nIj09HZGRkfD09OzxjL4vZCtcDA0Nld4bNmyY/K+EXxs3bhwA4NatWxqPR9cGfT11QvSB7DmosjP1\n7kyfPh1isRh37twZiLC0qqqqCowxlWfpnp6eaGpqwvLly7Fjxw4MGzZM43HI5vLb29uV3mttbYVI\nJFJql8Xc1Vm8vqOkTsgAMzY2RnV1ta7D6LeWlhYA6PYCJgDY2NggLS0N7u7uWotDdj2ivr5eob25\nuRktLS2ws7NT+ows0cv2gU9o+oWQAdTW1oZnz54N6ifn9JYsMaq6mcfa2hoWFhZajcPJyQmmpqa4\nf/++QrvsusPkyZOVPiN7GHlXZ/H6js7UCRlA+fn5YIxh5syZ8jaBQNDjtM1gZGNjA47jUFdX122f\ngbgTVyAQwN/fHxcvXoRUKoWBQee5al5eHjiO63IeXxazra2t1uMbaHSmTogWSaVS1NbWor29HUVF\nRYiKioKjoyPCwsLkfVxdXVFTU4OcnBy0tbWhurpa6awTAKysrFBRUYHy8nI0NDSgra0NeXl5OlvS\nKBaL4ezsjEePHnX5fmlpKWxtbRESEqL0XmhoKGxtbXH9+nWNxLJ582ZUVlZi69ataGpqwuXLl7Fn\nzx6EhYXBzc1Nqb8sZg8PD42MP5hQUiekG/v27cOMGTMAAJs2bUJQUBBSU1Oxd+9eAJ1/1v/000/4\n+OOPsWHDBgDA66+/jpKSEvk2Wlpa4OHhAZFIBB8fH4wfPx7nz59XmIdet24d5s2bhxUrVsDNzQ3b\nt2+XTwt4enrKlz+Gh4fDxsYGEydOhL+/P2pqagbkOKgSEBCA4uLiLleYqFoD3traiqqqKqUbg150\n5coVeHt7Y/To0bh69Spu3rwJOzs7zJo1CxcvXpT3c3d3x1dffYV//etfGDFiBIKDg/HWW2/hH//4\nR5fbvXbtGuzt7bucmtF7OrybtVegB7flksFnMJQJWLNmDbOystJpDOpS9/dWUlLCBAIB+/zzz9Ua\np6Ojg/n4+LC0tDR1Q+y3J0+eMKFQyD788EO1P6sP+YjO1AnRIr5XBHR1dUV8fDzi4+PR2NjYq890\ndHQgJycHDQ0NCA0N1XKEyuLi4jB16lREREQM+NgDgfdJffXq1TA1NQXHcSgsLNR1OP3Sm/KjPcnO\nzoazszM4jlN4GRkZwcbGBnPnzsWePXtQW1urwcgJn0VHR2PZsmUIDQ1VedFUJj8/H9nZ2cjLy+vx\nTlRNS0pKQmFhIc6cOaOVNfODAe+T+ieffIKPP/5Y12H0W2/Kj/ZGcHAwfvrpJ7i4uMDc3ByMMUil\nUlRVVSEzMxNOTk7YtGkT3N3d8f3332twD4aWmJgYHDp0CHV1dXByckJWVpauQ9KqhIQEREREYOfO\nnT329fX1xZEjRxTq3QyE3NxcPH/+HPn5+bC0tBzQsQcSLWnUAzdv3kR8fDzCw8PR1NSk8SJEHMfB\nwsICc+fOxdy5cxEQEICQkBAEBATg3r17MDc31+h4Q0FiYiISExN1HcaA8vPzg5+fn67D6FZQUBCC\ngoJ0HYbW8f5MHYBCOU591Jvyo5q0dOlShIWFoaqqCgcOHND6eIQQzeFdUmeMYc+ePXBzc4OxsTHM\nzc2xceNGpX4dHR3YsmULHB0dIRKJMHnyZGRkZADofXlVALhw4QJeffVViMVimJmZwcPDQ367sqox\ntEGTZVhl66jz8vLkbXw8ZoTwjo5X3/QIai4hio2NZRzHsb///e+straWNTc3s/379zMA7MaNG/J+\n7733HjM2NmZZWVmstraWxcTEMAMDA3bt2jX5dgCwc+fOsbq6OlZVVcV8fHyYiYkJa21tZYwx1tjY\nyMzMzNju3buZRCJhjx8/ZkuWLGHV1dW9GqMvfvvb33b79JcvvviCmZqasvj4+B634+LiwszNzbt9\nv76+ngFgY8aMkbfp0zEbDEsa9ZG6v7ehRh+Oz6D/1qtzEJubm5lYLGbz589XaD927JhCUpdIJEws\nFrPQ0FCFzxobG7N169Yxxv4vQcke0cUYk//jUFpayhhj7IcffmAA2BdffKEUS2/G6AtVSV0dPSV1\nxhjjOI5ZWFgwxvTvmFFS7xt9SFq6pA/Hh1cXSktLS9Hc3AxfX1+V/e7evYvm5mZMmjRJ3iYSiTBq\n1CiVJVFfLK/q7OwMGxsbrFq1CpGRkQgLC8PYsWP7NcZgIbsgK3tSjb4es2XLlvXpc0PZ3r17cfz4\ncV2HQfqIV3PqsnoO1tbWKvs1NTUBAN5//32Ftdr3799Xa7mgSCTC119/DW9vbyQkJMDZ2RmhoaGQ\nSCQaG0NX7t27BwCYMGECADpmhOgLXp2py4rly56E0h1Z0t+7dy+ioqL6Naa7uztOnTqF6upqJCUl\nYdeuXXB3d5ffKaeJMXThyy+/BND58F5Af48ZnXGqh+M4vPPOO0qP2COd9GElHa/O1CdNmgQDAwNc\nuHBBZb8xY8ZAKBT2+w7TiooK3L59G0Bn0tu5cydeeeUV3L59W2Nj6MLjx4+xd+9eODg44K233gJA\nx4wQfcGrpG5tbY3g4GBkZWUhLS0N9fX1KCoqwsGDBxX6CYVCvPnmmzh27BhSU1NRX1+Pjo4OPHr0\nCP/5z396PV5FRQXWrl2LO3fuoLW1FTdu3MD9+/cxc+ZMjY2hDnXLsDLG0NjYCKlUCsYYqqurkZGR\ngVmzZsHQ0BA5OTnyOXW+HjNCeEfHF2p7BDWvNjc0NLDVq1ezESNGsOHDhzNvb2+2ZcsWBoA5ODiw\nmzdvMsYYe/78Odu0aRNzdHRkAoGAWVtbs+DgYFZcXMz279/PxGIxA8DGjRvHysrK2MGDB5mZmRkD\nwF566SV27949Vl5ezry8vJilpSUzNDRko0ePZrGxsay9vb3HMdRx+fJlNmvWLGZnZ8cAMABs1KhR\nzMvLi124cEHe78yZM8zU1JTt2LGj222dPHmSTZ48mYnFYmZkZMQMDAwYAPlKl1dffZXFx8ezp0+f\nKn1Wn44ZrX7pG3V/b0ONPhwfjjEN33OuYRzHISMjg+b4iFoyMzMREhKi8ZIKfEe/N9X04fjwavqF\nEEKGOkrqOnDnzh2l0rddvXRRa5oQTTp79iyio6MhlUqxePFiODo6QigUwt7eHkFBQSgqKlJ7m7t3\n78aECRMgEolgYmKCCRMmYPPmzfJSEwBw8uRJ7N69m/f17LtCSV0HJkyYANZ5N6/KV3p6uq5DJaTP\ntm7dipSUFMTExEAqleLSpUs4evQoampqUFBQAIlEgtmzZ6OiokKt7V66dAlvv/02Hjx4gMrKSmzf\nvh27d+/G0qVL5X0CAwMhFArh6+uLZ8+eaXrXBjVK6oRoiUQi6dcDTQbLGH2xa9cupKenIzMzE6am\npgA6n7fq7e0NsVgMJycnJCQkoK6uDp999pla2zYyMsL69ethbW2N4cOHY9myZVi0aBH+53/+R2GV\nVGRkJKZMmQJ/f3+0t7drcvcGNUrqhGhJWloaqqqq9H4MdZWWlmLz5s3Ytm2b/IZAgUCAU6dOKfRz\ndnYGAJSVlam1/RMnTsi3K2Nvbw8ASo/Ui4uLQ2FhIZKTk9UaQ59RUifkfzHGkJSUhJdffhnGxsaw\ntLTEokWLFOrOREREwMjISOGpPevXr4eJiQk4jsOTJ08AAFFRUdiwYQPKysrAcRxcXV2RkpICoVAI\nGxsbrF27FnZ2dhAKhfDy8sLVq1c1Mgag2RLMfZGSkgLGGAIDA1X2k0gkACC/F6I/SkpKYGFhgZde\nekmh3dLSEnPmzEFycvLQWQmlg2WUaoEerAslg09f1qlv2bKFGRkZsc8//5w9e/aMFRUVsVdeeYWN\nHDmSPX78WN7vjTfeYLa2tgqf3bNnDwMgLyHMGGPBwcHMxcVFod+aNWuYiYkJu337NmtpaWHFxcVs\nxowZzNTUlD148EAjY6hTgvlFmvi9OTs7s4kTJ/bYLzs7mwFgWVlZfRqntbWVPXr0iH300UfM2NiY\nff755132i46OViq93Vf6kI/oTJ0QdJ41JiUlYcmSJVi1ahXMzc3h4eGBAwcO4MmTJ0p3JfeHQCCQ\n/zUwceJEpKamoqGhAYcOHdLI9gMCAlBfX4/NmzdrZHvqaGpqws8//wwXF5du+1RWViI9PR2RkZHw\n9PTs8Yy+O2PGjIGDgwPi4uLwwQcfICQkpMt+48aNAwDcunWrT+PoG0rqhAAoLi5GY2Mjpk+frtA+\nY8YMGBkZKUyPaNr06dMhFov1oiRzT6qqqsAYg1gs7raPp6cnIiMjsWjRIuTl5WHYsGF9Guvhw4eo\nqqrC0aNH8c9//hPTpk3r8vqCLJbKyso+jaNvKKkTAsiXvQ0fPlzpPQsLCzQ0NGh1fGNjY1RXV2t1\njIHQ0tICACqfpWtjY4Ovv/4aH330Ub8eaj5s2DBYW1vDz88P6enpm8WrYQAAA6dJREFUKC4u7vJh\n3yKRSCE2vqOkTgg6EzeALpP3s2fP4ODgoLWx29ratD7GQJElUFU3/VhbW8uPt6a4urrC0NAQxcXF\nSu+1trYqxMZ3lNQJQWfZ5uHDh+P7779XaL969SpaW1vxm9/8Rt4mEAjkT3LShPz8fDDGMHPmTK2N\nMVBsbGzAcRzq6uq67XPq1Cn5EkR1PX36FCtXrlRqLykpQUdHB8aMGaP0niwWW1vbPo2pbyipE4LO\n0sIbNmzAiRMncPjwYdTX1+PWrVsIDw+HnZ0d1qxZI+/r6uqKmpoa5OTkoK2tDdXV1bh//77SNq2s\nrFBRUYHy8nI0NDTIk7RUKkVtbS3a29tRVFSEqKgoODo6IiwsTCNjqFuCWZPEYjGcnZ3lTyF7UWlp\nKWxtbbu8qBkaGgpbW1tcv3692+2bmJjgX//6F77++mvU19ejra0NN27cwJ///GeYmJjg3XffVfqM\nLBYPD48+7pV+oaROyP/aunUrEhMTER8fj5EjR2LOnDkYO3Ys8vPzYWJiIu+3bt06zJs3DytWrICb\nmxu2b98u/9Pe09MTDx8+BACEh4fDxsYGEydOhL+/P2pqagB0zu16eHhAJBLBx8cH48ePx/nz5xXm\nofs7hi4FBASguLhYvg7915iKteKtra2oqqpCbm5ut32EQiFmzZqF1atXw97eHqampli2bBnGjh2L\nK1euKDzfVubatWuwt7fH5MmT+7ZD+kbHSyp7BD1YF0oGn8FaT33NmjXMyspK12F0SxO/t5KSEiYQ\nCLpdN96djo4O5uPjw9LS0vo1/q89efKECYVC9uGHH2pke/qQj+hMnZABxvfKga6uroiPj0d8fLzS\nbfvd6ejoQE5ODhoaGjRanTQuLg5Tp05FRESExrY52FFSJ4RoXHR0NJYtW4bQ0FCVF01l8vPzkZ2d\njby8PJVr3NWRlJSEwsJCnDlzps9r4fURJXVCBkhMTAwOHTqEuro6ODk5ISsrS9chaVVCQgIiIiKw\nc+fOHvv6+vriyJEjCvVu+iM3NxfPnz9Hfn4+LC0tNbJNfSHQdQCEDBWJiYld3hzDZ35+fvDz8xvw\ncYOCghAUFDTg4w4GdKZOCCE8QkmdEEJ4hJI6IYTwCCV1QgjhEUrqhBDCIxxjg/sZTxzH6ToEQgiR\ny8jIwPLly3UdRrcG/ZLGjIwMXYdACCFyXl5eug5BpUF/pk4IIaT3aE6dEEJ4hJI6IYTwCCV1Qgjh\nEQGA47oOghBCiGb8f+34dt7w9+7+AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttLfBQndj9f7",
        "colab_type": "text"
      },
      "source": [
        "**Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "trM94O2SkANM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8daa4e40-3bdd-45d7-dc94-1db7c584193d"
      },
      "source": [
        "EPOCHS = 500\n",
        "training_history = model.fit( X_train, y_train, validation_data=(X_test, y_test), epochs=EPOCHS, callbacks=[tensorboard_callback] )\n",
        "\n",
        "# %tensorboard --logdir logs/fit\n",
        "# %tensorboard --logdir logs\n",
        "# %tensorboard --logdir logs/gradient_tape\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 112 samples, validate on 38 samples\n",
            "Epoch 1/500\n",
            "112/112 [==============================] - 1s 7ms/sample - loss: 0.9944 - accuracy: 0.5714 - val_loss: 0.9721 - val_accuracy: 0.7632\n",
            "Epoch 2/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.9722 - accuracy: 0.5804 - val_loss: 0.9475 - val_accuracy: 0.7632\n",
            "Epoch 3/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.9534 - accuracy: 0.6071 - val_loss: 0.9232 - val_accuracy: 0.7895\n",
            "Epoch 4/500\n",
            "112/112 [==============================] - 0s 235us/sample - loss: 0.9337 - accuracy: 0.6339 - val_loss: 0.9007 - val_accuracy: 0.7895\n",
            "Epoch 5/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.9146 - accuracy: 0.6339 - val_loss: 0.8799 - val_accuracy: 0.8158\n",
            "Epoch 6/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.8972 - accuracy: 0.6696 - val_loss: 0.8595 - val_accuracy: 0.8158\n",
            "Epoch 7/500\n",
            "112/112 [==============================] - 0s 222us/sample - loss: 0.8818 - accuracy: 0.6696 - val_loss: 0.8399 - val_accuracy: 0.7895\n",
            "Epoch 8/500\n",
            "112/112 [==============================] - 0s 269us/sample - loss: 0.8648 - accuracy: 0.6964 - val_loss: 0.8219 - val_accuracy: 0.7895\n",
            "Epoch 9/500\n",
            "112/112 [==============================] - 0s 179us/sample - loss: 0.8510 - accuracy: 0.7232 - val_loss: 0.8046 - val_accuracy: 0.8421\n",
            "Epoch 10/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.8355 - accuracy: 0.7411 - val_loss: 0.7884 - val_accuracy: 0.8421\n",
            "Epoch 11/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.8218 - accuracy: 0.7411 - val_loss: 0.7727 - val_accuracy: 0.8421\n",
            "Epoch 12/500\n",
            "112/112 [==============================] - 0s 202us/sample - loss: 0.8081 - accuracy: 0.7589 - val_loss: 0.7579 - val_accuracy: 0.8421\n",
            "Epoch 13/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.7956 - accuracy: 0.7589 - val_loss: 0.7435 - val_accuracy: 0.8421\n",
            "Epoch 14/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.7833 - accuracy: 0.7589 - val_loss: 0.7297 - val_accuracy: 0.8421\n",
            "Epoch 15/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.7717 - accuracy: 0.7589 - val_loss: 0.7165 - val_accuracy: 0.8684\n",
            "Epoch 16/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.7600 - accuracy: 0.7589 - val_loss: 0.7043 - val_accuracy: 0.8421\n",
            "Epoch 17/500\n",
            "112/112 [==============================] - 0s 282us/sample - loss: 0.7492 - accuracy: 0.7589 - val_loss: 0.6923 - val_accuracy: 0.8421\n",
            "Epoch 18/500\n",
            "112/112 [==============================] - 0s 274us/sample - loss: 0.7385 - accuracy: 0.7946 - val_loss: 0.6805 - val_accuracy: 0.8158\n",
            "Epoch 19/500\n",
            "112/112 [==============================] - 0s 336us/sample - loss: 0.7282 - accuracy: 0.7946 - val_loss: 0.6691 - val_accuracy: 0.8158\n",
            "Epoch 20/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.7186 - accuracy: 0.7946 - val_loss: 0.6580 - val_accuracy: 0.8158\n",
            "Epoch 21/500\n",
            "112/112 [==============================] - 0s 253us/sample - loss: 0.7085 - accuracy: 0.7946 - val_loss: 0.6473 - val_accuracy: 0.8158\n",
            "Epoch 22/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.6993 - accuracy: 0.7857 - val_loss: 0.6371 - val_accuracy: 0.8158\n",
            "Epoch 23/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.6898 - accuracy: 0.7946 - val_loss: 0.6273 - val_accuracy: 0.8158\n",
            "Epoch 24/500\n",
            "112/112 [==============================] - 0s 224us/sample - loss: 0.6811 - accuracy: 0.7946 - val_loss: 0.6177 - val_accuracy: 0.8158\n",
            "Epoch 25/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.6723 - accuracy: 0.7946 - val_loss: 0.6087 - val_accuracy: 0.8158\n",
            "Epoch 26/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.6637 - accuracy: 0.8036 - val_loss: 0.5997 - val_accuracy: 0.8158\n",
            "Epoch 27/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.6555 - accuracy: 0.8036 - val_loss: 0.5909 - val_accuracy: 0.8421\n",
            "Epoch 28/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.6471 - accuracy: 0.8036 - val_loss: 0.5825 - val_accuracy: 0.8421\n",
            "Epoch 29/500\n",
            "112/112 [==============================] - 0s 246us/sample - loss: 0.6395 - accuracy: 0.8036 - val_loss: 0.5741 - val_accuracy: 0.8421\n",
            "Epoch 30/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.6314 - accuracy: 0.8125 - val_loss: 0.5662 - val_accuracy: 0.8421\n",
            "Epoch 31/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.6238 - accuracy: 0.8125 - val_loss: 0.5585 - val_accuracy: 0.8421\n",
            "Epoch 32/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.6168 - accuracy: 0.8125 - val_loss: 0.5508 - val_accuracy: 0.8421\n",
            "Epoch 33/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.6093 - accuracy: 0.8214 - val_loss: 0.5432 - val_accuracy: 0.8421\n",
            "Epoch 34/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.6026 - accuracy: 0.8214 - val_loss: 0.5358 - val_accuracy: 0.8421\n",
            "Epoch 35/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.5954 - accuracy: 0.8214 - val_loss: 0.5287 - val_accuracy: 0.8421\n",
            "Epoch 36/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.5889 - accuracy: 0.8214 - val_loss: 0.5217 - val_accuracy: 0.8421\n",
            "Epoch 37/500\n",
            "112/112 [==============================] - 0s 258us/sample - loss: 0.5823 - accuracy: 0.8214 - val_loss: 0.5150 - val_accuracy: 0.8421\n",
            "Epoch 38/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.5758 - accuracy: 0.8214 - val_loss: 0.5083 - val_accuracy: 0.8421\n",
            "Epoch 39/500\n",
            "112/112 [==============================] - 0s 251us/sample - loss: 0.5697 - accuracy: 0.8304 - val_loss: 0.5018 - val_accuracy: 0.8421\n",
            "Epoch 40/500\n",
            "112/112 [==============================] - 0s 265us/sample - loss: 0.5635 - accuracy: 0.8304 - val_loss: 0.4955 - val_accuracy: 0.8421\n",
            "Epoch 41/500\n",
            "112/112 [==============================] - 0s 237us/sample - loss: 0.5577 - accuracy: 0.8304 - val_loss: 0.4894 - val_accuracy: 0.8421\n",
            "Epoch 42/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.5521 - accuracy: 0.8304 - val_loss: 0.4835 - val_accuracy: 0.8421\n",
            "Epoch 43/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.5463 - accuracy: 0.8304 - val_loss: 0.4778 - val_accuracy: 0.8684\n",
            "Epoch 44/500\n",
            "112/112 [==============================] - 0s 290us/sample - loss: 0.5408 - accuracy: 0.8304 - val_loss: 0.4722 - val_accuracy: 0.8684\n",
            "Epoch 45/500\n",
            "112/112 [==============================] - 0s 245us/sample - loss: 0.5355 - accuracy: 0.8304 - val_loss: 0.4666 - val_accuracy: 0.8684\n",
            "Epoch 46/500\n",
            "112/112 [==============================] - 0s 230us/sample - loss: 0.5302 - accuracy: 0.8304 - val_loss: 0.4611 - val_accuracy: 0.8684\n",
            "Epoch 47/500\n",
            "112/112 [==============================] - 0s 247us/sample - loss: 0.5250 - accuracy: 0.8304 - val_loss: 0.4558 - val_accuracy: 0.8684\n",
            "Epoch 48/500\n",
            "112/112 [==============================] - 0s 229us/sample - loss: 0.5201 - accuracy: 0.8304 - val_loss: 0.4507 - val_accuracy: 0.8684\n",
            "Epoch 49/500\n",
            "112/112 [==============================] - 0s 250us/sample - loss: 0.5150 - accuracy: 0.8304 - val_loss: 0.4457 - val_accuracy: 0.8684\n",
            "Epoch 50/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.5103 - accuracy: 0.8304 - val_loss: 0.4408 - val_accuracy: 0.8684\n",
            "Epoch 51/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.5057 - accuracy: 0.8304 - val_loss: 0.4360 - val_accuracy: 0.8684\n",
            "Epoch 52/500\n",
            "112/112 [==============================] - 0s 290us/sample - loss: 0.5013 - accuracy: 0.8214 - val_loss: 0.4314 - val_accuracy: 0.8684\n",
            "Epoch 53/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.4967 - accuracy: 0.8214 - val_loss: 0.4269 - val_accuracy: 0.8684\n",
            "Epoch 54/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.4926 - accuracy: 0.8214 - val_loss: 0.4226 - val_accuracy: 0.8684\n",
            "Epoch 55/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.4884 - accuracy: 0.8214 - val_loss: 0.4183 - val_accuracy: 0.8684\n",
            "Epoch 56/500\n",
            "112/112 [==============================] - 0s 234us/sample - loss: 0.4844 - accuracy: 0.8214 - val_loss: 0.4142 - val_accuracy: 0.8684\n",
            "Epoch 57/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.4803 - accuracy: 0.8214 - val_loss: 0.4101 - val_accuracy: 0.8684\n",
            "Epoch 58/500\n",
            "112/112 [==============================] - 0s 273us/sample - loss: 0.4766 - accuracy: 0.8214 - val_loss: 0.4061 - val_accuracy: 0.8684\n",
            "Epoch 59/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.4728 - accuracy: 0.8214 - val_loss: 0.4021 - val_accuracy: 0.8684\n",
            "Epoch 60/500\n",
            "112/112 [==============================] - 0s 216us/sample - loss: 0.4690 - accuracy: 0.8214 - val_loss: 0.3982 - val_accuracy: 0.8684\n",
            "Epoch 61/500\n",
            "112/112 [==============================] - 0s 326us/sample - loss: 0.4653 - accuracy: 0.8214 - val_loss: 0.3944 - val_accuracy: 0.8684\n",
            "Epoch 62/500\n",
            "112/112 [==============================] - 0s 269us/sample - loss: 0.4618 - accuracy: 0.8214 - val_loss: 0.3907 - val_accuracy: 0.8684\n",
            "Epoch 63/500\n",
            "112/112 [==============================] - 0s 235us/sample - loss: 0.4583 - accuracy: 0.8214 - val_loss: 0.3871 - val_accuracy: 0.8684\n",
            "Epoch 64/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.4548 - accuracy: 0.8304 - val_loss: 0.3834 - val_accuracy: 0.8684\n",
            "Epoch 65/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.4514 - accuracy: 0.8304 - val_loss: 0.3798 - val_accuracy: 0.8684\n",
            "Epoch 66/500\n",
            "112/112 [==============================] - 0s 246us/sample - loss: 0.4481 - accuracy: 0.8304 - val_loss: 0.3763 - val_accuracy: 0.8684\n",
            "Epoch 67/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.4450 - accuracy: 0.8304 - val_loss: 0.3730 - val_accuracy: 0.8684\n",
            "Epoch 68/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.4417 - accuracy: 0.8304 - val_loss: 0.3698 - val_accuracy: 0.8684\n",
            "Epoch 69/500\n",
            "112/112 [==============================] - 0s 265us/sample - loss: 0.4387 - accuracy: 0.8304 - val_loss: 0.3667 - val_accuracy: 0.8684\n",
            "Epoch 70/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.4357 - accuracy: 0.8304 - val_loss: 0.3636 - val_accuracy: 0.8684\n",
            "Epoch 71/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.4327 - accuracy: 0.8304 - val_loss: 0.3607 - val_accuracy: 0.8684\n",
            "Epoch 72/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.4298 - accuracy: 0.8304 - val_loss: 0.3578 - val_accuracy: 0.8684\n",
            "Epoch 73/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.4270 - accuracy: 0.8304 - val_loss: 0.3551 - val_accuracy: 0.8684\n",
            "Epoch 74/500\n",
            "112/112 [==============================] - 0s 235us/sample - loss: 0.4243 - accuracy: 0.8304 - val_loss: 0.3523 - val_accuracy: 0.8684\n",
            "Epoch 75/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.4215 - accuracy: 0.8304 - val_loss: 0.3497 - val_accuracy: 0.8684\n",
            "Epoch 76/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.4190 - accuracy: 0.8304 - val_loss: 0.3470 - val_accuracy: 0.8684\n",
            "Epoch 77/500\n",
            "112/112 [==============================] - 0s 196us/sample - loss: 0.4163 - accuracy: 0.8304 - val_loss: 0.3443 - val_accuracy: 0.8684\n",
            "Epoch 78/500\n",
            "112/112 [==============================] - 0s 239us/sample - loss: 0.4138 - accuracy: 0.8304 - val_loss: 0.3416 - val_accuracy: 0.8684\n",
            "Epoch 79/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.4112 - accuracy: 0.8304 - val_loss: 0.3391 - val_accuracy: 0.8684\n",
            "Epoch 80/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.4087 - accuracy: 0.8304 - val_loss: 0.3366 - val_accuracy: 0.8684\n",
            "Epoch 81/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.4062 - accuracy: 0.8304 - val_loss: 0.3340 - val_accuracy: 0.8684\n",
            "Epoch 82/500\n",
            "112/112 [==============================] - 0s 238us/sample - loss: 0.4037 - accuracy: 0.8304 - val_loss: 0.3315 - val_accuracy: 0.8684\n",
            "Epoch 83/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.4014 - accuracy: 0.8393 - val_loss: 0.3291 - val_accuracy: 0.8684\n",
            "Epoch 84/500\n",
            "112/112 [==============================] - 0s 216us/sample - loss: 0.3990 - accuracy: 0.8393 - val_loss: 0.3267 - val_accuracy: 0.8684\n",
            "Epoch 85/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.3967 - accuracy: 0.8393 - val_loss: 0.3245 - val_accuracy: 0.8684\n",
            "Epoch 86/500\n",
            "112/112 [==============================] - 0s 224us/sample - loss: 0.3944 - accuracy: 0.8393 - val_loss: 0.3222 - val_accuracy: 0.8684\n",
            "Epoch 87/500\n",
            "112/112 [==============================] - 0s 211us/sample - loss: 0.3922 - accuracy: 0.8393 - val_loss: 0.3200 - val_accuracy: 0.8684\n",
            "Epoch 88/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.3899 - accuracy: 0.8393 - val_loss: 0.3179 - val_accuracy: 0.8684\n",
            "Epoch 89/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.3878 - accuracy: 0.8393 - val_loss: 0.3158 - val_accuracy: 0.8684\n",
            "Epoch 90/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.3857 - accuracy: 0.8393 - val_loss: 0.3137 - val_accuracy: 0.8684\n",
            "Epoch 91/500\n",
            "112/112 [==============================] - 0s 227us/sample - loss: 0.3835 - accuracy: 0.8393 - val_loss: 0.3117 - val_accuracy: 0.8684\n",
            "Epoch 92/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.3815 - accuracy: 0.8393 - val_loss: 0.3096 - val_accuracy: 0.8684\n",
            "Epoch 93/500\n",
            "112/112 [==============================] - 0s 197us/sample - loss: 0.3793 - accuracy: 0.8482 - val_loss: 0.3076 - val_accuracy: 0.8684\n",
            "Epoch 94/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.3774 - accuracy: 0.8482 - val_loss: 0.3055 - val_accuracy: 0.8684\n",
            "Epoch 95/500\n",
            "112/112 [==============================] - 0s 197us/sample - loss: 0.3753 - accuracy: 0.8482 - val_loss: 0.3036 - val_accuracy: 0.8684\n",
            "Epoch 96/500\n",
            "112/112 [==============================] - 0s 338us/sample - loss: 0.3734 - accuracy: 0.8482 - val_loss: 0.3015 - val_accuracy: 0.8684\n",
            "Epoch 97/500\n",
            "112/112 [==============================] - 0s 211us/sample - loss: 0.3713 - accuracy: 0.8571 - val_loss: 0.2995 - val_accuracy: 0.8684\n",
            "Epoch 98/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.3694 - accuracy: 0.8571 - val_loss: 0.2975 - val_accuracy: 0.8684\n",
            "Epoch 99/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.3673 - accuracy: 0.8571 - val_loss: 0.2955 - val_accuracy: 0.8684\n",
            "Epoch 100/500\n",
            "112/112 [==============================] - 0s 242us/sample - loss: 0.3654 - accuracy: 0.8661 - val_loss: 0.2935 - val_accuracy: 0.8684\n",
            "Epoch 101/500\n",
            "112/112 [==============================] - 0s 186us/sample - loss: 0.3635 - accuracy: 0.8661 - val_loss: 0.2914 - val_accuracy: 0.8684\n",
            "Epoch 102/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.3615 - accuracy: 0.8661 - val_loss: 0.2895 - val_accuracy: 0.8684\n",
            "Epoch 103/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.3596 - accuracy: 0.8661 - val_loss: 0.2876 - val_accuracy: 0.8684\n",
            "Epoch 104/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.3578 - accuracy: 0.8661 - val_loss: 0.2856 - val_accuracy: 0.8684\n",
            "Epoch 105/500\n",
            "112/112 [==============================] - 0s 227us/sample - loss: 0.3557 - accuracy: 0.8661 - val_loss: 0.2838 - val_accuracy: 0.8947\n",
            "Epoch 106/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.3539 - accuracy: 0.8661 - val_loss: 0.2819 - val_accuracy: 0.8947\n",
            "Epoch 107/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.3520 - accuracy: 0.8661 - val_loss: 0.2800 - val_accuracy: 0.8947\n",
            "Epoch 108/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.3502 - accuracy: 0.8661 - val_loss: 0.2782 - val_accuracy: 0.8947\n",
            "Epoch 109/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.3484 - accuracy: 0.8661 - val_loss: 0.2764 - val_accuracy: 0.8947\n",
            "Epoch 110/500\n",
            "112/112 [==============================] - 0s 192us/sample - loss: 0.3466 - accuracy: 0.8661 - val_loss: 0.2748 - val_accuracy: 0.8947\n",
            "Epoch 111/500\n",
            "112/112 [==============================] - 0s 238us/sample - loss: 0.3449 - accuracy: 0.8750 - val_loss: 0.2731 - val_accuracy: 0.8947\n",
            "Epoch 112/500\n",
            "112/112 [==============================] - 0s 271us/sample - loss: 0.3430 - accuracy: 0.8750 - val_loss: 0.2714 - val_accuracy: 0.8947\n",
            "Epoch 113/500\n",
            "112/112 [==============================] - 0s 233us/sample - loss: 0.3413 - accuracy: 0.8750 - val_loss: 0.2698 - val_accuracy: 0.8947\n",
            "Epoch 114/500\n",
            "112/112 [==============================] - 0s 244us/sample - loss: 0.3395 - accuracy: 0.8750 - val_loss: 0.2681 - val_accuracy: 0.8947\n",
            "Epoch 115/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.3377 - accuracy: 0.8750 - val_loss: 0.2663 - val_accuracy: 0.8947\n",
            "Epoch 116/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.3360 - accuracy: 0.8929 - val_loss: 0.2645 - val_accuracy: 0.8947\n",
            "Epoch 117/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.3342 - accuracy: 0.8929 - val_loss: 0.2628 - val_accuracy: 0.8947\n",
            "Epoch 118/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.3324 - accuracy: 0.8929 - val_loss: 0.2611 - val_accuracy: 0.8947\n",
            "Epoch 119/500\n",
            "112/112 [==============================] - 0s 230us/sample - loss: 0.3307 - accuracy: 0.8929 - val_loss: 0.2593 - val_accuracy: 0.8947\n",
            "Epoch 120/500\n",
            "112/112 [==============================] - 0s 252us/sample - loss: 0.3290 - accuracy: 0.8929 - val_loss: 0.2576 - val_accuracy: 0.8947\n",
            "Epoch 121/500\n",
            "112/112 [==============================] - 0s 292us/sample - loss: 0.3273 - accuracy: 0.8929 - val_loss: 0.2559 - val_accuracy: 0.8947\n",
            "Epoch 122/500\n",
            "112/112 [==============================] - 0s 237us/sample - loss: 0.3255 - accuracy: 0.8929 - val_loss: 0.2543 - val_accuracy: 0.8947\n",
            "Epoch 123/500\n",
            "112/112 [==============================] - 0s 245us/sample - loss: 0.3237 - accuracy: 0.8929 - val_loss: 0.2527 - val_accuracy: 0.8947\n",
            "Epoch 124/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.3221 - accuracy: 0.8929 - val_loss: 0.2511 - val_accuracy: 0.8947\n",
            "Epoch 125/500\n",
            "112/112 [==============================] - 0s 257us/sample - loss: 0.3203 - accuracy: 0.8929 - val_loss: 0.2494 - val_accuracy: 0.8947\n",
            "Epoch 126/500\n",
            "112/112 [==============================] - 0s 312us/sample - loss: 0.3188 - accuracy: 0.8929 - val_loss: 0.2477 - val_accuracy: 0.8947\n",
            "Epoch 127/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.3171 - accuracy: 0.8929 - val_loss: 0.2462 - val_accuracy: 0.8947\n",
            "Epoch 128/500\n",
            "112/112 [==============================] - 0s 216us/sample - loss: 0.3154 - accuracy: 0.8929 - val_loss: 0.2446 - val_accuracy: 0.8947\n",
            "Epoch 129/500\n",
            "112/112 [==============================] - 0s 242us/sample - loss: 0.3137 - accuracy: 0.8929 - val_loss: 0.2430 - val_accuracy: 0.8947\n",
            "Epoch 130/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.3122 - accuracy: 0.8929 - val_loss: 0.2414 - val_accuracy: 0.8947\n",
            "Epoch 131/500\n",
            "112/112 [==============================] - 0s 207us/sample - loss: 0.3106 - accuracy: 0.8929 - val_loss: 0.2399 - val_accuracy: 0.8947\n",
            "Epoch 132/500\n",
            "112/112 [==============================] - 0s 303us/sample - loss: 0.3092 - accuracy: 0.8929 - val_loss: 0.2383 - val_accuracy: 0.8947\n",
            "Epoch 133/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.3075 - accuracy: 0.8929 - val_loss: 0.2369 - val_accuracy: 0.8947\n",
            "Epoch 134/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.3060 - accuracy: 0.8929 - val_loss: 0.2354 - val_accuracy: 0.8947\n",
            "Epoch 135/500\n",
            "112/112 [==============================] - 0s 276us/sample - loss: 0.3046 - accuracy: 0.8929 - val_loss: 0.2338 - val_accuracy: 0.8947\n",
            "Epoch 136/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.3030 - accuracy: 0.8929 - val_loss: 0.2323 - val_accuracy: 0.8947\n",
            "Epoch 137/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.3014 - accuracy: 0.8929 - val_loss: 0.2308 - val_accuracy: 0.8947\n",
            "Epoch 138/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.2999 - accuracy: 0.8929 - val_loss: 0.2294 - val_accuracy: 0.8947\n",
            "Epoch 139/500\n",
            "112/112 [==============================] - 0s 236us/sample - loss: 0.2986 - accuracy: 0.8929 - val_loss: 0.2280 - val_accuracy: 0.9211\n",
            "Epoch 140/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.2970 - accuracy: 0.9018 - val_loss: 0.2266 - val_accuracy: 0.9211\n",
            "Epoch 141/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.2955 - accuracy: 0.9018 - val_loss: 0.2253 - val_accuracy: 0.9211\n",
            "Epoch 142/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.2942 - accuracy: 0.9107 - val_loss: 0.2238 - val_accuracy: 0.9211\n",
            "Epoch 143/500\n",
            "112/112 [==============================] - 0s 239us/sample - loss: 0.2927 - accuracy: 0.9107 - val_loss: 0.2225 - val_accuracy: 0.9211\n",
            "Epoch 144/500\n",
            "112/112 [==============================] - 0s 260us/sample - loss: 0.2912 - accuracy: 0.9107 - val_loss: 0.2211 - val_accuracy: 0.9211\n",
            "Epoch 145/500\n",
            "112/112 [==============================] - 0s 233us/sample - loss: 0.2898 - accuracy: 0.9107 - val_loss: 0.2196 - val_accuracy: 0.9211\n",
            "Epoch 146/500\n",
            "112/112 [==============================] - 0s 294us/sample - loss: 0.2884 - accuracy: 0.9107 - val_loss: 0.2180 - val_accuracy: 0.9211\n",
            "Epoch 147/500\n",
            "112/112 [==============================] - 0s 211us/sample - loss: 0.2871 - accuracy: 0.9107 - val_loss: 0.2165 - val_accuracy: 0.9211\n",
            "Epoch 148/500\n",
            "112/112 [==============================] - 0s 207us/sample - loss: 0.2855 - accuracy: 0.9107 - val_loss: 0.2150 - val_accuracy: 0.9211\n",
            "Epoch 149/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.2841 - accuracy: 0.9107 - val_loss: 0.2136 - val_accuracy: 0.9211\n",
            "Epoch 150/500\n",
            "112/112 [==============================] - 0s 230us/sample - loss: 0.2826 - accuracy: 0.9107 - val_loss: 0.2122 - val_accuracy: 0.9211\n",
            "Epoch 151/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.2811 - accuracy: 0.9107 - val_loss: 0.2109 - val_accuracy: 0.9211\n",
            "Epoch 152/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.2798 - accuracy: 0.9107 - val_loss: 0.2096 - val_accuracy: 0.9211\n",
            "Epoch 153/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.2783 - accuracy: 0.9107 - val_loss: 0.2083 - val_accuracy: 0.9211\n",
            "Epoch 154/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.2770 - accuracy: 0.9196 - val_loss: 0.2070 - val_accuracy: 0.9211\n",
            "Epoch 155/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.2755 - accuracy: 0.9196 - val_loss: 0.2057 - val_accuracy: 0.9211\n",
            "Epoch 156/500\n",
            "112/112 [==============================] - 0s 247us/sample - loss: 0.2741 - accuracy: 0.9196 - val_loss: 0.2043 - val_accuracy: 0.9211\n",
            "Epoch 157/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.2727 - accuracy: 0.9196 - val_loss: 0.2030 - val_accuracy: 0.9211\n",
            "Epoch 158/500\n",
            "112/112 [==============================] - 0s 202us/sample - loss: 0.2713 - accuracy: 0.9196 - val_loss: 0.2017 - val_accuracy: 0.9474\n",
            "Epoch 159/500\n",
            "112/112 [==============================] - 0s 192us/sample - loss: 0.2699 - accuracy: 0.9196 - val_loss: 0.2004 - val_accuracy: 0.9474\n",
            "Epoch 160/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.2684 - accuracy: 0.9196 - val_loss: 0.1991 - val_accuracy: 0.9474\n",
            "Epoch 161/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.2670 - accuracy: 0.9196 - val_loss: 0.1978 - val_accuracy: 0.9474\n",
            "Epoch 162/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.2656 - accuracy: 0.9196 - val_loss: 0.1965 - val_accuracy: 0.9474\n",
            "Epoch 163/500\n",
            "112/112 [==============================] - 0s 192us/sample - loss: 0.2642 - accuracy: 0.9196 - val_loss: 0.1952 - val_accuracy: 0.9474\n",
            "Epoch 164/500\n",
            "112/112 [==============================] - 0s 197us/sample - loss: 0.2627 - accuracy: 0.9196 - val_loss: 0.1940 - val_accuracy: 0.9474\n",
            "Epoch 165/500\n",
            "112/112 [==============================] - 0s 232us/sample - loss: 0.2612 - accuracy: 0.9196 - val_loss: 0.1927 - val_accuracy: 0.9474\n",
            "Epoch 166/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.2599 - accuracy: 0.9196 - val_loss: 0.1913 - val_accuracy: 0.9474\n",
            "Epoch 167/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.2585 - accuracy: 0.9196 - val_loss: 0.1901 - val_accuracy: 0.9474\n",
            "Epoch 168/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.2571 - accuracy: 0.9196 - val_loss: 0.1888 - val_accuracy: 0.9474\n",
            "Epoch 169/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.2557 - accuracy: 0.9196 - val_loss: 0.1874 - val_accuracy: 0.9474\n",
            "Epoch 170/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.2543 - accuracy: 0.9196 - val_loss: 0.1861 - val_accuracy: 0.9474\n",
            "Epoch 171/500\n",
            "112/112 [==============================] - 0s 216us/sample - loss: 0.2529 - accuracy: 0.9286 - val_loss: 0.1847 - val_accuracy: 0.9474\n",
            "Epoch 172/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.2515 - accuracy: 0.9286 - val_loss: 0.1833 - val_accuracy: 0.9474\n",
            "Epoch 173/500\n",
            "112/112 [==============================] - 0s 273us/sample - loss: 0.2500 - accuracy: 0.9286 - val_loss: 0.1819 - val_accuracy: 0.9474\n",
            "Epoch 174/500\n",
            "112/112 [==============================] - 0s 177us/sample - loss: 0.2486 - accuracy: 0.9286 - val_loss: 0.1806 - val_accuracy: 0.9737\n",
            "Epoch 175/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.2473 - accuracy: 0.9286 - val_loss: 0.1793 - val_accuracy: 0.9737\n",
            "Epoch 176/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.2457 - accuracy: 0.9286 - val_loss: 0.1779 - val_accuracy: 0.9737\n",
            "Epoch 177/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.2443 - accuracy: 0.9286 - val_loss: 0.1767 - val_accuracy: 0.9737\n",
            "Epoch 178/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.2429 - accuracy: 0.9286 - val_loss: 0.1754 - val_accuracy: 0.9737\n",
            "Epoch 179/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.2415 - accuracy: 0.9286 - val_loss: 0.1742 - val_accuracy: 0.9737\n",
            "Epoch 180/500\n",
            "112/112 [==============================] - 0s 216us/sample - loss: 0.2402 - accuracy: 0.9286 - val_loss: 0.1729 - val_accuracy: 0.9737\n",
            "Epoch 181/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.2387 - accuracy: 0.9286 - val_loss: 0.1717 - val_accuracy: 0.9737\n",
            "Epoch 182/500\n",
            "112/112 [==============================] - 0s 234us/sample - loss: 0.2374 - accuracy: 0.9286 - val_loss: 0.1706 - val_accuracy: 0.9737\n",
            "Epoch 183/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.2359 - accuracy: 0.9286 - val_loss: 0.1694 - val_accuracy: 0.9737\n",
            "Epoch 184/500\n",
            "112/112 [==============================] - 0s 186us/sample - loss: 0.2346 - accuracy: 0.9286 - val_loss: 0.1682 - val_accuracy: 0.9737\n",
            "Epoch 185/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.2332 - accuracy: 0.9286 - val_loss: 0.1670 - val_accuracy: 0.9737\n",
            "Epoch 186/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.2318 - accuracy: 0.9286 - val_loss: 0.1659 - val_accuracy: 0.9737\n",
            "Epoch 187/500\n",
            "112/112 [==============================] - 0s 222us/sample - loss: 0.2305 - accuracy: 0.9286 - val_loss: 0.1647 - val_accuracy: 0.9737\n",
            "Epoch 188/500\n",
            "112/112 [==============================] - 0s 232us/sample - loss: 0.2292 - accuracy: 0.9286 - val_loss: 0.1635 - val_accuracy: 0.9737\n",
            "Epoch 189/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.2280 - accuracy: 0.9286 - val_loss: 0.1625 - val_accuracy: 0.9737\n",
            "Epoch 190/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.2266 - accuracy: 0.9196 - val_loss: 0.1614 - val_accuracy: 0.9737\n",
            "Epoch 191/500\n",
            "112/112 [==============================] - 0s 222us/sample - loss: 0.2253 - accuracy: 0.9196 - val_loss: 0.1603 - val_accuracy: 1.0000\n",
            "Epoch 192/500\n",
            "112/112 [==============================] - 0s 207us/sample - loss: 0.2240 - accuracy: 0.9196 - val_loss: 0.1592 - val_accuracy: 1.0000\n",
            "Epoch 193/500\n",
            "112/112 [==============================] - 0s 202us/sample - loss: 0.2227 - accuracy: 0.9286 - val_loss: 0.1581 - val_accuracy: 1.0000\n",
            "Epoch 194/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.2215 - accuracy: 0.9286 - val_loss: 0.1570 - val_accuracy: 1.0000\n",
            "Epoch 195/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.2202 - accuracy: 0.9286 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
            "Epoch 196/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.2189 - accuracy: 0.9286 - val_loss: 0.1548 - val_accuracy: 1.0000\n",
            "Epoch 197/500\n",
            "112/112 [==============================] - 0s 272us/sample - loss: 0.2177 - accuracy: 0.9286 - val_loss: 0.1539 - val_accuracy: 1.0000\n",
            "Epoch 198/500\n",
            "112/112 [==============================] - 0s 235us/sample - loss: 0.2166 - accuracy: 0.9286 - val_loss: 0.1529 - val_accuracy: 1.0000\n",
            "Epoch 199/500\n",
            "112/112 [==============================] - 0s 254us/sample - loss: 0.2154 - accuracy: 0.9286 - val_loss: 0.1519 - val_accuracy: 1.0000\n",
            "Epoch 200/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.2142 - accuracy: 0.9286 - val_loss: 0.1509 - val_accuracy: 1.0000\n",
            "Epoch 201/500\n",
            "112/112 [==============================] - 0s 228us/sample - loss: 0.2130 - accuracy: 0.9286 - val_loss: 0.1498 - val_accuracy: 1.0000\n",
            "Epoch 202/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.2118 - accuracy: 0.9286 - val_loss: 0.1486 - val_accuracy: 1.0000\n",
            "Epoch 203/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.2106 - accuracy: 0.9286 - val_loss: 0.1475 - val_accuracy: 1.0000\n",
            "Epoch 204/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.2094 - accuracy: 0.9286 - val_loss: 0.1465 - val_accuracy: 1.0000\n",
            "Epoch 205/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.2082 - accuracy: 0.9286 - val_loss: 0.1455 - val_accuracy: 1.0000\n",
            "Epoch 206/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.2071 - accuracy: 0.9286 - val_loss: 0.1445 - val_accuracy: 1.0000\n",
            "Epoch 207/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.2061 - accuracy: 0.9286 - val_loss: 0.1435 - val_accuracy: 1.0000\n",
            "Epoch 208/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.2048 - accuracy: 0.9375 - val_loss: 0.1425 - val_accuracy: 1.0000\n",
            "Epoch 209/500\n",
            "112/112 [==============================] - 0s 261us/sample - loss: 0.2037 - accuracy: 0.9375 - val_loss: 0.1414 - val_accuracy: 1.0000\n",
            "Epoch 210/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.2026 - accuracy: 0.9375 - val_loss: 0.1404 - val_accuracy: 1.0000\n",
            "Epoch 211/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.2016 - accuracy: 0.9375 - val_loss: 0.1394 - val_accuracy: 1.0000\n",
            "Epoch 212/500\n",
            "112/112 [==============================] - 0s 196us/sample - loss: 0.2004 - accuracy: 0.9375 - val_loss: 0.1384 - val_accuracy: 1.0000\n",
            "Epoch 213/500\n",
            "112/112 [==============================] - 0s 224us/sample - loss: 0.1993 - accuracy: 0.9375 - val_loss: 0.1375 - val_accuracy: 1.0000\n",
            "Epoch 214/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.1981 - accuracy: 0.9375 - val_loss: 0.1366 - val_accuracy: 1.0000\n",
            "Epoch 215/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.1969 - accuracy: 0.9375 - val_loss: 0.1357 - val_accuracy: 1.0000\n",
            "Epoch 216/500\n",
            "112/112 [==============================] - 0s 202us/sample - loss: 0.1958 - accuracy: 0.9375 - val_loss: 0.1348 - val_accuracy: 1.0000\n",
            "Epoch 217/500\n",
            "112/112 [==============================] - 0s 239us/sample - loss: 0.1947 - accuracy: 0.9375 - val_loss: 0.1339 - val_accuracy: 1.0000\n",
            "Epoch 218/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.1935 - accuracy: 0.9375 - val_loss: 0.1330 - val_accuracy: 1.0000\n",
            "Epoch 219/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.1924 - accuracy: 0.9375 - val_loss: 0.1322 - val_accuracy: 1.0000\n",
            "Epoch 220/500\n",
            "112/112 [==============================] - 0s 176us/sample - loss: 0.1912 - accuracy: 0.9375 - val_loss: 0.1313 - val_accuracy: 1.0000\n",
            "Epoch 221/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.1900 - accuracy: 0.9375 - val_loss: 0.1304 - val_accuracy: 1.0000\n",
            "Epoch 222/500\n",
            "112/112 [==============================] - 0s 244us/sample - loss: 0.1889 - accuracy: 0.9375 - val_loss: 0.1296 - val_accuracy: 1.0000\n",
            "Epoch 223/500\n",
            "112/112 [==============================] - 0s 232us/sample - loss: 0.1878 - accuracy: 0.9375 - val_loss: 0.1288 - val_accuracy: 1.0000\n",
            "Epoch 224/500\n",
            "112/112 [==============================] - 0s 245us/sample - loss: 0.1867 - accuracy: 0.9375 - val_loss: 0.1280 - val_accuracy: 1.0000\n",
            "Epoch 225/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.1855 - accuracy: 0.9375 - val_loss: 0.1272 - val_accuracy: 1.0000\n",
            "Epoch 226/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.1844 - accuracy: 0.9375 - val_loss: 0.1264 - val_accuracy: 1.0000\n",
            "Epoch 227/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.1832 - accuracy: 0.9375 - val_loss: 0.1255 - val_accuracy: 1.0000\n",
            "Epoch 228/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.1823 - accuracy: 0.9375 - val_loss: 0.1246 - val_accuracy: 1.0000\n",
            "Epoch 229/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.1813 - accuracy: 0.9375 - val_loss: 0.1237 - val_accuracy: 1.0000\n",
            "Epoch 230/500\n",
            "112/112 [==============================] - 0s 212us/sample - loss: 0.1800 - accuracy: 0.9375 - val_loss: 0.1229 - val_accuracy: 1.0000\n",
            "Epoch 231/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.1789 - accuracy: 0.9375 - val_loss: 0.1222 - val_accuracy: 1.0000\n",
            "Epoch 232/500\n",
            "112/112 [==============================] - 0s 305us/sample - loss: 0.1778 - accuracy: 0.9375 - val_loss: 0.1214 - val_accuracy: 1.0000\n",
            "Epoch 233/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.1767 - accuracy: 0.9375 - val_loss: 0.1208 - val_accuracy: 1.0000\n",
            "Epoch 234/500\n",
            "112/112 [==============================] - 0s 229us/sample - loss: 0.1755 - accuracy: 0.9375 - val_loss: 0.1201 - val_accuracy: 1.0000\n",
            "Epoch 235/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.1745 - accuracy: 0.9375 - val_loss: 0.1196 - val_accuracy: 1.0000\n",
            "Epoch 236/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.1735 - accuracy: 0.9375 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
            "Epoch 237/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.1724 - accuracy: 0.9375 - val_loss: 0.1180 - val_accuracy: 1.0000\n",
            "Epoch 238/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.1714 - accuracy: 0.9375 - val_loss: 0.1172 - val_accuracy: 1.0000\n",
            "Epoch 239/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.1705 - accuracy: 0.9375 - val_loss: 0.1166 - val_accuracy: 1.0000\n",
            "Epoch 240/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.1695 - accuracy: 0.9375 - val_loss: 0.1157 - val_accuracy: 1.0000\n",
            "Epoch 241/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.1683 - accuracy: 0.9375 - val_loss: 0.1149 - val_accuracy: 1.0000\n",
            "Epoch 242/500\n",
            "112/112 [==============================] - 0s 258us/sample - loss: 0.1672 - accuracy: 0.9375 - val_loss: 0.1143 - val_accuracy: 1.0000\n",
            "Epoch 243/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.1662 - accuracy: 0.9375 - val_loss: 0.1135 - val_accuracy: 1.0000\n",
            "Epoch 244/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.1652 - accuracy: 0.9375 - val_loss: 0.1127 - val_accuracy: 1.0000\n",
            "Epoch 245/500\n",
            "112/112 [==============================] - 0s 232us/sample - loss: 0.1642 - accuracy: 0.9375 - val_loss: 0.1118 - val_accuracy: 1.0000\n",
            "Epoch 246/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.1632 - accuracy: 0.9375 - val_loss: 0.1109 - val_accuracy: 1.0000\n",
            "Epoch 247/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.1623 - accuracy: 0.9375 - val_loss: 0.1101 - val_accuracy: 1.0000\n",
            "Epoch 248/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.1613 - accuracy: 0.9375 - val_loss: 0.1094 - val_accuracy: 1.0000\n",
            "Epoch 249/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.1603 - accuracy: 0.9375 - val_loss: 0.1087 - val_accuracy: 1.0000\n",
            "Epoch 250/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.1596 - accuracy: 0.9375 - val_loss: 0.1078 - val_accuracy: 1.0000\n",
            "Epoch 251/500\n",
            "112/112 [==============================] - 0s 227us/sample - loss: 0.1583 - accuracy: 0.9375 - val_loss: 0.1070 - val_accuracy: 1.0000\n",
            "Epoch 252/500\n",
            "112/112 [==============================] - 0s 229us/sample - loss: 0.1574 - accuracy: 0.9375 - val_loss: 0.1063 - val_accuracy: 1.0000\n",
            "Epoch 253/500\n",
            "112/112 [==============================] - 0s 212us/sample - loss: 0.1565 - accuracy: 0.9375 - val_loss: 0.1055 - val_accuracy: 1.0000\n",
            "Epoch 254/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.1555 - accuracy: 0.9375 - val_loss: 0.1048 - val_accuracy: 1.0000\n",
            "Epoch 255/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.1546 - accuracy: 0.9375 - val_loss: 0.1039 - val_accuracy: 1.0000\n",
            "Epoch 256/500\n",
            "112/112 [==============================] - 0s 184us/sample - loss: 0.1537 - accuracy: 0.9375 - val_loss: 0.1033 - val_accuracy: 1.0000\n",
            "Epoch 257/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.1531 - accuracy: 0.9375 - val_loss: 0.1028 - val_accuracy: 1.0000\n",
            "Epoch 258/500\n",
            "112/112 [==============================] - 0s 172us/sample - loss: 0.1520 - accuracy: 0.9375 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
            "Epoch 259/500\n",
            "112/112 [==============================] - 0s 182us/sample - loss: 0.1511 - accuracy: 0.9375 - val_loss: 0.1014 - val_accuracy: 1.0000\n",
            "Epoch 260/500\n",
            "112/112 [==============================] - 0s 171us/sample - loss: 0.1502 - accuracy: 0.9375 - val_loss: 0.1007 - val_accuracy: 1.0000\n",
            "Epoch 261/500\n",
            "112/112 [==============================] - 0s 172us/sample - loss: 0.1494 - accuracy: 0.9375 - val_loss: 0.1000 - val_accuracy: 1.0000\n",
            "Epoch 262/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.1485 - accuracy: 0.9375 - val_loss: 0.0993 - val_accuracy: 1.0000\n",
            "Epoch 263/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.1479 - accuracy: 0.9375 - val_loss: 0.0987 - val_accuracy: 1.0000\n",
            "Epoch 264/500\n",
            "112/112 [==============================] - 0s 173us/sample - loss: 0.1470 - accuracy: 0.9375 - val_loss: 0.0980 - val_accuracy: 1.0000\n",
            "Epoch 265/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.1461 - accuracy: 0.9375 - val_loss: 0.0973 - val_accuracy: 1.0000\n",
            "Epoch 266/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.1453 - accuracy: 0.9375 - val_loss: 0.0966 - val_accuracy: 1.0000\n",
            "Epoch 267/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.1446 - accuracy: 0.9375 - val_loss: 0.0959 - val_accuracy: 1.0000\n",
            "Epoch 268/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.1440 - accuracy: 0.9375 - val_loss: 0.0951 - val_accuracy: 1.0000\n",
            "Epoch 269/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.1431 - accuracy: 0.9375 - val_loss: 0.0945 - val_accuracy: 1.0000\n",
            "Epoch 270/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.1423 - accuracy: 0.9375 - val_loss: 0.0938 - val_accuracy: 1.0000\n",
            "Epoch 271/500\n",
            "112/112 [==============================] - 0s 174us/sample - loss: 0.1417 - accuracy: 0.9375 - val_loss: 0.0934 - val_accuracy: 1.0000\n",
            "Epoch 272/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.1409 - accuracy: 0.9375 - val_loss: 0.0929 - val_accuracy: 1.0000\n",
            "Epoch 273/500\n",
            "112/112 [==============================] - 0s 207us/sample - loss: 0.1401 - accuracy: 0.9375 - val_loss: 0.0924 - val_accuracy: 1.0000\n",
            "Epoch 274/500\n",
            "112/112 [==============================] - 0s 169us/sample - loss: 0.1394 - accuracy: 0.9375 - val_loss: 0.0918 - val_accuracy: 1.0000\n",
            "Epoch 275/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.1387 - accuracy: 0.9375 - val_loss: 0.0913 - val_accuracy: 1.0000\n",
            "Epoch 276/500\n",
            "112/112 [==============================] - 0s 179us/sample - loss: 0.1379 - accuracy: 0.9375 - val_loss: 0.0907 - val_accuracy: 1.0000\n",
            "Epoch 277/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.1372 - accuracy: 0.9375 - val_loss: 0.0903 - val_accuracy: 1.0000\n",
            "Epoch 278/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.1365 - accuracy: 0.9375 - val_loss: 0.0898 - val_accuracy: 1.0000\n",
            "Epoch 279/500\n",
            "112/112 [==============================] - 0s 192us/sample - loss: 0.1359 - accuracy: 0.9375 - val_loss: 0.0892 - val_accuracy: 1.0000\n",
            "Epoch 280/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.1351 - accuracy: 0.9375 - val_loss: 0.0888 - val_accuracy: 1.0000\n",
            "Epoch 281/500\n",
            "112/112 [==============================] - 0s 177us/sample - loss: 0.1345 - accuracy: 0.9375 - val_loss: 0.0883 - val_accuracy: 1.0000\n",
            "Epoch 282/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.1337 - accuracy: 0.9375 - val_loss: 0.0878 - val_accuracy: 1.0000\n",
            "Epoch 283/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.1331 - accuracy: 0.9375 - val_loss: 0.0873 - val_accuracy: 1.0000\n",
            "Epoch 284/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.1326 - accuracy: 0.9375 - val_loss: 0.0870 - val_accuracy: 1.0000\n",
            "Epoch 285/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.1320 - accuracy: 0.9375 - val_loss: 0.0865 - val_accuracy: 1.0000\n",
            "Epoch 286/500\n",
            "112/112 [==============================] - 0s 186us/sample - loss: 0.1312 - accuracy: 0.9375 - val_loss: 0.0861 - val_accuracy: 1.0000\n",
            "Epoch 287/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.1306 - accuracy: 0.9375 - val_loss: 0.0856 - val_accuracy: 1.0000\n",
            "Epoch 288/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.1299 - accuracy: 0.9375 - val_loss: 0.0850 - val_accuracy: 1.0000\n",
            "Epoch 289/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.1293 - accuracy: 0.9375 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
            "Epoch 290/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.1287 - accuracy: 0.9375 - val_loss: 0.0842 - val_accuracy: 1.0000\n",
            "Epoch 291/500\n",
            "112/112 [==============================] - 0s 234us/sample - loss: 0.1283 - accuracy: 0.9375 - val_loss: 0.0839 - val_accuracy: 1.0000\n",
            "Epoch 292/500\n",
            "112/112 [==============================] - 0s 327us/sample - loss: 0.1275 - accuracy: 0.9464 - val_loss: 0.0834 - val_accuracy: 1.0000\n",
            "Epoch 293/500\n",
            "112/112 [==============================] - 0s 247us/sample - loss: 0.1269 - accuracy: 0.9464 - val_loss: 0.0830 - val_accuracy: 1.0000\n",
            "Epoch 294/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.1263 - accuracy: 0.9464 - val_loss: 0.0824 - val_accuracy: 1.0000\n",
            "Epoch 295/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.1258 - accuracy: 0.9464 - val_loss: 0.0820 - val_accuracy: 1.0000\n",
            "Epoch 296/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.1252 - accuracy: 0.9464 - val_loss: 0.0815 - val_accuracy: 1.0000\n",
            "Epoch 297/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.1246 - accuracy: 0.9464 - val_loss: 0.0810 - val_accuracy: 1.0000\n",
            "Epoch 298/500\n",
            "112/112 [==============================] - 0s 248us/sample - loss: 0.1242 - accuracy: 0.9464 - val_loss: 0.0807 - val_accuracy: 1.0000\n",
            "Epoch 299/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.1237 - accuracy: 0.9464 - val_loss: 0.0803 - val_accuracy: 1.0000\n",
            "Epoch 300/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.1230 - accuracy: 0.9464 - val_loss: 0.0800 - val_accuracy: 1.0000\n",
            "Epoch 301/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.1225 - accuracy: 0.9464 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
            "Epoch 302/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.1220 - accuracy: 0.9464 - val_loss: 0.0793 - val_accuracy: 1.0000\n",
            "Epoch 303/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.1213 - accuracy: 0.9554 - val_loss: 0.0790 - val_accuracy: 1.0000\n",
            "Epoch 304/500\n",
            "112/112 [==============================] - 0s 221us/sample - loss: 0.1208 - accuracy: 0.9554 - val_loss: 0.0787 - val_accuracy: 1.0000\n",
            "Epoch 305/500\n",
            "112/112 [==============================] - 0s 176us/sample - loss: 0.1203 - accuracy: 0.9554 - val_loss: 0.0784 - val_accuracy: 1.0000\n",
            "Epoch 306/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.1198 - accuracy: 0.9554 - val_loss: 0.0781 - val_accuracy: 1.0000\n",
            "Epoch 307/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.1192 - accuracy: 0.9554 - val_loss: 0.0777 - val_accuracy: 1.0000\n",
            "Epoch 308/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.1188 - accuracy: 0.9554 - val_loss: 0.0774 - val_accuracy: 1.0000\n",
            "Epoch 309/500\n",
            "112/112 [==============================] - 0s 159us/sample - loss: 0.1182 - accuracy: 0.9554 - val_loss: 0.0770 - val_accuracy: 1.0000\n",
            "Epoch 310/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.1178 - accuracy: 0.9554 - val_loss: 0.0767 - val_accuracy: 1.0000\n",
            "Epoch 311/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.1173 - accuracy: 0.9554 - val_loss: 0.0763 - val_accuracy: 1.0000\n",
            "Epoch 312/500\n",
            "112/112 [==============================] - 0s 234us/sample - loss: 0.1168 - accuracy: 0.9554 - val_loss: 0.0759 - val_accuracy: 1.0000\n",
            "Epoch 313/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.1163 - accuracy: 0.9643 - val_loss: 0.0756 - val_accuracy: 1.0000\n",
            "Epoch 314/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.1159 - accuracy: 0.9643 - val_loss: 0.0753 - val_accuracy: 1.0000\n",
            "Epoch 315/500\n",
            "112/112 [==============================] - 0s 160us/sample - loss: 0.1153 - accuracy: 0.9643 - val_loss: 0.0750 - val_accuracy: 1.0000\n",
            "Epoch 316/500\n",
            "112/112 [==============================] - 0s 196us/sample - loss: 0.1149 - accuracy: 0.9643 - val_loss: 0.0747 - val_accuracy: 1.0000\n",
            "Epoch 317/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.1144 - accuracy: 0.9643 - val_loss: 0.0745 - val_accuracy: 1.0000\n",
            "Epoch 318/500\n",
            "112/112 [==============================] - 0s 178us/sample - loss: 0.1139 - accuracy: 0.9643 - val_loss: 0.0741 - val_accuracy: 1.0000\n",
            "Epoch 319/500\n",
            "112/112 [==============================] - 0s 169us/sample - loss: 0.1137 - accuracy: 0.9643 - val_loss: 0.0736 - val_accuracy: 1.0000\n",
            "Epoch 320/500\n",
            "112/112 [==============================] - 0s 177us/sample - loss: 0.1131 - accuracy: 0.9643 - val_loss: 0.0733 - val_accuracy: 1.0000\n",
            "Epoch 321/500\n",
            "112/112 [==============================] - 0s 173us/sample - loss: 0.1126 - accuracy: 0.9643 - val_loss: 0.0730 - val_accuracy: 1.0000\n",
            "Epoch 322/500\n",
            "112/112 [==============================] - 0s 179us/sample - loss: 0.1122 - accuracy: 0.9643 - val_loss: 0.0727 - val_accuracy: 1.0000\n",
            "Epoch 323/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.1117 - accuracy: 0.9643 - val_loss: 0.0723 - val_accuracy: 1.0000\n",
            "Epoch 324/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.1113 - accuracy: 0.9643 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
            "Epoch 325/500\n",
            "112/112 [==============================] - 0s 225us/sample - loss: 0.1109 - accuracy: 0.9643 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
            "Epoch 326/500\n",
            "112/112 [==============================] - 0s 173us/sample - loss: 0.1106 - accuracy: 0.9643 - val_loss: 0.0715 - val_accuracy: 1.0000\n",
            "Epoch 327/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.1100 - accuracy: 0.9643 - val_loss: 0.0711 - val_accuracy: 1.0000\n",
            "Epoch 328/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.1097 - accuracy: 0.9643 - val_loss: 0.0707 - val_accuracy: 1.0000\n",
            "Epoch 329/500\n",
            "112/112 [==============================] - 0s 175us/sample - loss: 0.1092 - accuracy: 0.9643 - val_loss: 0.0703 - val_accuracy: 1.0000\n",
            "Epoch 330/500\n",
            "112/112 [==============================] - 0s 224us/sample - loss: 0.1087 - accuracy: 0.9643 - val_loss: 0.0699 - val_accuracy: 1.0000\n",
            "Epoch 331/500\n",
            "112/112 [==============================] - 0s 173us/sample - loss: 0.1084 - accuracy: 0.9643 - val_loss: 0.0693 - val_accuracy: 1.0000\n",
            "Epoch 332/500\n",
            "112/112 [==============================] - 0s 165us/sample - loss: 0.1079 - accuracy: 0.9643 - val_loss: 0.0690 - val_accuracy: 1.0000\n",
            "Epoch 333/500\n",
            "112/112 [==============================] - 0s 184us/sample - loss: 0.1076 - accuracy: 0.9643 - val_loss: 0.0688 - val_accuracy: 1.0000\n",
            "Epoch 334/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.1071 - accuracy: 0.9643 - val_loss: 0.0684 - val_accuracy: 1.0000\n",
            "Epoch 335/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.1068 - accuracy: 0.9643 - val_loss: 0.0681 - val_accuracy: 1.0000\n",
            "Epoch 336/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.1063 - accuracy: 0.9643 - val_loss: 0.0677 - val_accuracy: 1.0000\n",
            "Epoch 337/500\n",
            "112/112 [==============================] - 0s 170us/sample - loss: 0.1060 - accuracy: 0.9643 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
            "Epoch 338/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.1056 - accuracy: 0.9643 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
            "Epoch 339/500\n",
            "112/112 [==============================] - 0s 207us/sample - loss: 0.1054 - accuracy: 0.9643 - val_loss: 0.0673 - val_accuracy: 1.0000\n",
            "Epoch 340/500\n",
            "112/112 [==============================] - 0s 177us/sample - loss: 0.1049 - accuracy: 0.9643 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
            "Epoch 341/500\n",
            "112/112 [==============================] - 0s 174us/sample - loss: 0.1045 - accuracy: 0.9643 - val_loss: 0.0667 - val_accuracy: 1.0000\n",
            "Epoch 342/500\n",
            "112/112 [==============================] - 0s 166us/sample - loss: 0.1041 - accuracy: 0.9643 - val_loss: 0.0663 - val_accuracy: 1.0000\n",
            "Epoch 343/500\n",
            "112/112 [==============================] - 0s 174us/sample - loss: 0.1039 - accuracy: 0.9643 - val_loss: 0.0662 - val_accuracy: 1.0000\n",
            "Epoch 344/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.1035 - accuracy: 0.9643 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 345/500\n",
            "112/112 [==============================] - 0s 178us/sample - loss: 0.1032 - accuracy: 0.9643 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
            "Epoch 346/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.1029 - accuracy: 0.9643 - val_loss: 0.0658 - val_accuracy: 1.0000\n",
            "Epoch 347/500\n",
            "112/112 [==============================] - 0s 238us/sample - loss: 0.1023 - accuracy: 0.9643 - val_loss: 0.0654 - val_accuracy: 1.0000\n",
            "Epoch 348/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.1019 - accuracy: 0.9643 - val_loss: 0.0650 - val_accuracy: 1.0000\n",
            "Epoch 349/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.1016 - accuracy: 0.9643 - val_loss: 0.0646 - val_accuracy: 1.0000\n",
            "Epoch 350/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.1013 - accuracy: 0.9643 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
            "Epoch 351/500\n",
            "112/112 [==============================] - 0s 172us/sample - loss: 0.1012 - accuracy: 0.9643 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 352/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.1008 - accuracy: 0.9643 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 353/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.1005 - accuracy: 0.9643 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 354/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.1000 - accuracy: 0.9643 - val_loss: 0.0639 - val_accuracy: 1.0000\n",
            "Epoch 355/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.0997 - accuracy: 0.9643 - val_loss: 0.0640 - val_accuracy: 1.0000\n",
            "Epoch 356/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.0994 - accuracy: 0.9643 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
            "Epoch 357/500\n",
            "112/112 [==============================] - 0s 179us/sample - loss: 0.0991 - accuracy: 0.9643 - val_loss: 0.0644 - val_accuracy: 1.0000\n",
            "Epoch 358/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.0989 - accuracy: 0.9554 - val_loss: 0.0643 - val_accuracy: 1.0000\n",
            "Epoch 359/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.0986 - accuracy: 0.9554 - val_loss: 0.0638 - val_accuracy: 1.0000\n",
            "Epoch 360/500\n",
            "112/112 [==============================] - 0s 176us/sample - loss: 0.0981 - accuracy: 0.9554 - val_loss: 0.0635 - val_accuracy: 1.0000\n",
            "Epoch 361/500\n",
            "112/112 [==============================] - 0s 211us/sample - loss: 0.0978 - accuracy: 0.9643 - val_loss: 0.0632 - val_accuracy: 1.0000\n",
            "Epoch 362/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.0976 - accuracy: 0.9643 - val_loss: 0.0630 - val_accuracy: 1.0000\n",
            "Epoch 363/500\n",
            "112/112 [==============================] - 0s 248us/sample - loss: 0.0972 - accuracy: 0.9643 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
            "Epoch 364/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.0969 - accuracy: 0.9643 - val_loss: 0.0624 - val_accuracy: 1.0000\n",
            "Epoch 365/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.0966 - accuracy: 0.9643 - val_loss: 0.0622 - val_accuracy: 1.0000\n",
            "Epoch 366/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.0963 - accuracy: 0.9643 - val_loss: 0.0620 - val_accuracy: 1.0000\n",
            "Epoch 367/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.0961 - accuracy: 0.9643 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
            "Epoch 368/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.0958 - accuracy: 0.9554 - val_loss: 0.0619 - val_accuracy: 1.0000\n",
            "Epoch 369/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.0955 - accuracy: 0.9554 - val_loss: 0.0615 - val_accuracy: 1.0000\n",
            "Epoch 370/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.0952 - accuracy: 0.9554 - val_loss: 0.0613 - val_accuracy: 1.0000\n",
            "Epoch 371/500\n",
            "112/112 [==============================] - 0s 172us/sample - loss: 0.0949 - accuracy: 0.9554 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 372/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0948 - accuracy: 0.9554 - val_loss: 0.0610 - val_accuracy: 1.0000\n",
            "Epoch 373/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.0946 - accuracy: 0.9554 - val_loss: 0.0607 - val_accuracy: 1.0000\n",
            "Epoch 374/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.0942 - accuracy: 0.9554 - val_loss: 0.0604 - val_accuracy: 1.0000\n",
            "Epoch 375/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.0939 - accuracy: 0.9554 - val_loss: 0.0602 - val_accuracy: 1.0000\n",
            "Epoch 376/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.0936 - accuracy: 0.9554 - val_loss: 0.0600 - val_accuracy: 1.0000\n",
            "Epoch 377/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.0933 - accuracy: 0.9554 - val_loss: 0.0598 - val_accuracy: 1.0000\n",
            "Epoch 378/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.0931 - accuracy: 0.9554 - val_loss: 0.0595 - val_accuracy: 1.0000\n",
            "Epoch 379/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.0927 - accuracy: 0.9554 - val_loss: 0.0593 - val_accuracy: 1.0000\n",
            "Epoch 380/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.0926 - accuracy: 0.9643 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 381/500\n",
            "112/112 [==============================] - 0s 177us/sample - loss: 0.0922 - accuracy: 0.9643 - val_loss: 0.0590 - val_accuracy: 1.0000\n",
            "Epoch 382/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.0919 - accuracy: 0.9643 - val_loss: 0.0589 - val_accuracy: 1.0000\n",
            "Epoch 383/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.0918 - accuracy: 0.9554 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 384/500\n",
            "112/112 [==============================] - 0s 241us/sample - loss: 0.0914 - accuracy: 0.9554 - val_loss: 0.0588 - val_accuracy: 1.0000\n",
            "Epoch 385/500\n",
            "112/112 [==============================] - 0s 219us/sample - loss: 0.0912 - accuracy: 0.9554 - val_loss: 0.0586 - val_accuracy: 1.0000\n",
            "Epoch 386/500\n",
            "112/112 [==============================] - 0s 212us/sample - loss: 0.0910 - accuracy: 0.9554 - val_loss: 0.0583 - val_accuracy: 1.0000\n",
            "Epoch 387/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.0907 - accuracy: 0.9554 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 388/500\n",
            "112/112 [==============================] - 0s 226us/sample - loss: 0.0906 - accuracy: 0.9554 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 389/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.0902 - accuracy: 0.9554 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 390/500\n",
            "112/112 [==============================] - 0s 174us/sample - loss: 0.0899 - accuracy: 0.9554 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 391/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.0898 - accuracy: 0.9554 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
            "Epoch 392/500\n",
            "112/112 [==============================] - 0s 166us/sample - loss: 0.0896 - accuracy: 0.9554 - val_loss: 0.0581 - val_accuracy: 1.0000\n",
            "Epoch 393/500\n",
            "112/112 [==============================] - 0s 167us/sample - loss: 0.0893 - accuracy: 0.9554 - val_loss: 0.0579 - val_accuracy: 1.0000\n",
            "Epoch 394/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.0890 - accuracy: 0.9554 - val_loss: 0.0576 - val_accuracy: 1.0000\n",
            "Epoch 395/500\n",
            "112/112 [==============================] - 0s 176us/sample - loss: 0.0888 - accuracy: 0.9554 - val_loss: 0.0574 - val_accuracy: 1.0000\n",
            "Epoch 396/500\n",
            "112/112 [==============================] - 0s 167us/sample - loss: 0.0886 - accuracy: 0.9554 - val_loss: 0.0571 - val_accuracy: 1.0000\n",
            "Epoch 397/500\n",
            "112/112 [==============================] - 0s 204us/sample - loss: 0.0884 - accuracy: 0.9554 - val_loss: 0.0569 - val_accuracy: 1.0000\n",
            "Epoch 398/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.0881 - accuracy: 0.9554 - val_loss: 0.0567 - val_accuracy: 1.0000\n",
            "Epoch 399/500\n",
            "112/112 [==============================] - 0s 176us/sample - loss: 0.0879 - accuracy: 0.9554 - val_loss: 0.0565 - val_accuracy: 1.0000\n",
            "Epoch 400/500\n",
            "112/112 [==============================] - 0s 222us/sample - loss: 0.0876 - accuracy: 0.9643 - val_loss: 0.0563 - val_accuracy: 1.0000\n",
            "Epoch 401/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.0874 - accuracy: 0.9643 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
            "Epoch 402/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.0872 - accuracy: 0.9643 - val_loss: 0.0560 - val_accuracy: 1.0000\n",
            "Epoch 403/500\n",
            "112/112 [==============================] - 0s 196us/sample - loss: 0.0870 - accuracy: 0.9643 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
            "Epoch 404/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0867 - accuracy: 0.9643 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
            "Epoch 405/500\n",
            "112/112 [==============================] - 0s 172us/sample - loss: 0.0865 - accuracy: 0.9554 - val_loss: 0.0558 - val_accuracy: 1.0000\n",
            "Epoch 406/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.0863 - accuracy: 0.9554 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
            "Epoch 407/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.0862 - accuracy: 0.9554 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 408/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.0865 - accuracy: 0.9554 - val_loss: 0.0556 - val_accuracy: 1.0000\n",
            "Epoch 409/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0859 - accuracy: 0.9554 - val_loss: 0.0555 - val_accuracy: 1.0000\n",
            "Epoch 410/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.0855 - accuracy: 0.9554 - val_loss: 0.0552 - val_accuracy: 1.0000\n",
            "Epoch 411/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0852 - accuracy: 0.9554 - val_loss: 0.0549 - val_accuracy: 1.0000\n",
            "Epoch 412/500\n",
            "112/112 [==============================] - 0s 184us/sample - loss: 0.0851 - accuracy: 0.9643 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
            "Epoch 413/500\n",
            "112/112 [==============================] - 0s 231us/sample - loss: 0.0850 - accuracy: 0.9643 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
            "Epoch 414/500\n",
            "112/112 [==============================] - 0s 184us/sample - loss: 0.0848 - accuracy: 0.9643 - val_loss: 0.0548 - val_accuracy: 1.0000\n",
            "Epoch 415/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.0845 - accuracy: 0.9643 - val_loss: 0.0547 - val_accuracy: 1.0000\n",
            "Epoch 416/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.0843 - accuracy: 0.9643 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 417/500\n",
            "112/112 [==============================] - 0s 205us/sample - loss: 0.0842 - accuracy: 0.9554 - val_loss: 0.0546 - val_accuracy: 1.0000\n",
            "Epoch 418/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.0840 - accuracy: 0.9554 - val_loss: 0.0543 - val_accuracy: 1.0000\n",
            "Epoch 419/500\n",
            "112/112 [==============================] - 0s 218us/sample - loss: 0.0838 - accuracy: 0.9554 - val_loss: 0.0542 - val_accuracy: 1.0000\n",
            "Epoch 420/500\n",
            "112/112 [==============================] - 0s 212us/sample - loss: 0.0836 - accuracy: 0.9554 - val_loss: 0.0540 - val_accuracy: 1.0000\n",
            "Epoch 421/500\n",
            "112/112 [==============================] - 0s 276us/sample - loss: 0.0834 - accuracy: 0.9554 - val_loss: 0.0538 - val_accuracy: 1.0000\n",
            "Epoch 422/500\n",
            "112/112 [==============================] - 0s 240us/sample - loss: 0.0832 - accuracy: 0.9643 - val_loss: 0.0535 - val_accuracy: 1.0000\n",
            "Epoch 423/500\n",
            "112/112 [==============================] - 0s 261us/sample - loss: 0.0832 - accuracy: 0.9643 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
            "Epoch 424/500\n",
            "112/112 [==============================] - 0s 222us/sample - loss: 0.0828 - accuracy: 0.9643 - val_loss: 0.0530 - val_accuracy: 1.0000\n",
            "Epoch 425/500\n",
            "112/112 [==============================] - 0s 260us/sample - loss: 0.0828 - accuracy: 0.9643 - val_loss: 0.0528 - val_accuracy: 1.0000\n",
            "Epoch 426/500\n",
            "112/112 [==============================] - 0s 241us/sample - loss: 0.0825 - accuracy: 0.9643 - val_loss: 0.0525 - val_accuracy: 1.0000\n",
            "Epoch 427/500\n",
            "112/112 [==============================] - 0s 181us/sample - loss: 0.0824 - accuracy: 0.9643 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
            "Epoch 428/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.0821 - accuracy: 0.9643 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
            "Epoch 429/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.0820 - accuracy: 0.9643 - val_loss: 0.0519 - val_accuracy: 1.0000\n",
            "Epoch 430/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.0818 - accuracy: 0.9643 - val_loss: 0.0517 - val_accuracy: 1.0000\n",
            "Epoch 431/500\n",
            "112/112 [==============================] - 0s 191us/sample - loss: 0.0817 - accuracy: 0.9643 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 432/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.0814 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 433/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.0812 - accuracy: 0.9643 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 434/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.0810 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 435/500\n",
            "112/112 [==============================] - 0s 170us/sample - loss: 0.0809 - accuracy: 0.9643 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
            "Epoch 436/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.0808 - accuracy: 0.9643 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
            "Epoch 437/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.0805 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 438/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0803 - accuracy: 0.9643 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 439/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.0801 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 440/500\n",
            "112/112 [==============================] - 0s 199us/sample - loss: 0.0800 - accuracy: 0.9643 - val_loss: 0.0516 - val_accuracy: 1.0000\n",
            "Epoch 441/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.0800 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 442/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.0798 - accuracy: 0.9643 - val_loss: 0.0515 - val_accuracy: 1.0000\n",
            "Epoch 443/500\n",
            "112/112 [==============================] - 0s 213us/sample - loss: 0.0796 - accuracy: 0.9643 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
            "Epoch 444/500\n",
            "112/112 [==============================] - 0s 203us/sample - loss: 0.0793 - accuracy: 0.9643 - val_loss: 0.0509 - val_accuracy: 1.0000\n",
            "Epoch 445/500\n",
            "112/112 [==============================] - 0s 168us/sample - loss: 0.0792 - accuracy: 0.9643 - val_loss: 0.0507 - val_accuracy: 1.0000\n",
            "Epoch 446/500\n",
            "112/112 [==============================] - 0s 198us/sample - loss: 0.0790 - accuracy: 0.9643 - val_loss: 0.0505 - val_accuracy: 1.0000\n",
            "Epoch 447/500\n",
            "112/112 [==============================] - 0s 183us/sample - loss: 0.0788 - accuracy: 0.9643 - val_loss: 0.0502 - val_accuracy: 1.0000\n",
            "Epoch 448/500\n",
            "112/112 [==============================] - 0s 186us/sample - loss: 0.0788 - accuracy: 0.9643 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
            "Epoch 449/500\n",
            "112/112 [==============================] - 0s 217us/sample - loss: 0.0785 - accuracy: 0.9643 - val_loss: 0.0496 - val_accuracy: 1.0000\n",
            "Epoch 450/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.0783 - accuracy: 0.9643 - val_loss: 0.0494 - val_accuracy: 1.0000\n",
            "Epoch 451/500\n",
            "112/112 [==============================] - 0s 178us/sample - loss: 0.0782 - accuracy: 0.9643 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 452/500\n",
            "112/112 [==============================] - 0s 175us/sample - loss: 0.0781 - accuracy: 0.9643 - val_loss: 0.0492 - val_accuracy: 1.0000\n",
            "Epoch 453/500\n",
            "112/112 [==============================] - 0s 200us/sample - loss: 0.0778 - accuracy: 0.9643 - val_loss: 0.0491 - val_accuracy: 1.0000\n",
            "Epoch 454/500\n",
            "112/112 [==============================] - 0s 179us/sample - loss: 0.0777 - accuracy: 0.9643 - val_loss: 0.0489 - val_accuracy: 1.0000\n",
            "Epoch 455/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.0775 - accuracy: 0.9643 - val_loss: 0.0488 - val_accuracy: 1.0000\n",
            "Epoch 456/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.0775 - accuracy: 0.9643 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
            "Epoch 457/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.0773 - accuracy: 0.9643 - val_loss: 0.0485 - val_accuracy: 1.0000\n",
            "Epoch 458/500\n",
            "112/112 [==============================] - 0s 192us/sample - loss: 0.0772 - accuracy: 0.9732 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
            "Epoch 459/500\n",
            "112/112 [==============================] - 0s 202us/sample - loss: 0.0770 - accuracy: 0.9732 - val_loss: 0.0484 - val_accuracy: 1.0000\n",
            "Epoch 460/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.0769 - accuracy: 0.9732 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 461/500\n",
            "112/112 [==============================] - 0s 190us/sample - loss: 0.0767 - accuracy: 0.9732 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 462/500\n",
            "112/112 [==============================] - 0s 193us/sample - loss: 0.0766 - accuracy: 0.9732 - val_loss: 0.0481 - val_accuracy: 1.0000\n",
            "Epoch 463/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.0764 - accuracy: 0.9732 - val_loss: 0.0480 - val_accuracy: 1.0000\n",
            "Epoch 464/500\n",
            "112/112 [==============================] - 0s 188us/sample - loss: 0.0763 - accuracy: 0.9732 - val_loss: 0.0478 - val_accuracy: 1.0000\n",
            "Epoch 465/500\n",
            "112/112 [==============================] - 0s 194us/sample - loss: 0.0762 - accuracy: 0.9732 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
            "Epoch 466/500\n",
            "112/112 [==============================] - 0s 187us/sample - loss: 0.0760 - accuracy: 0.9732 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "Epoch 467/500\n",
            "112/112 [==============================] - 0s 186us/sample - loss: 0.0758 - accuracy: 0.9732 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 468/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.0757 - accuracy: 0.9732 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "Epoch 469/500\n",
            "112/112 [==============================] - 0s 180us/sample - loss: 0.0755 - accuracy: 0.9732 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 470/500\n",
            "112/112 [==============================] - 0s 317us/sample - loss: 0.0754 - accuracy: 0.9732 - val_loss: 0.0477 - val_accuracy: 1.0000\n",
            "Epoch 471/500\n",
            "112/112 [==============================] - 0s 189us/sample - loss: 0.0753 - accuracy: 0.9732 - val_loss: 0.0476 - val_accuracy: 1.0000\n",
            "Epoch 472/500\n",
            "112/112 [==============================] - 0s 208us/sample - loss: 0.0751 - accuracy: 0.9732 - val_loss: 0.0475 - val_accuracy: 1.0000\n",
            "Epoch 473/500\n",
            "112/112 [==============================] - 0s 195us/sample - loss: 0.0749 - accuracy: 0.9732 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 474/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.0750 - accuracy: 0.9732 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
            "Epoch 475/500\n",
            "112/112 [==============================] - 0s 223us/sample - loss: 0.0748 - accuracy: 0.9732 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
            "Epoch 476/500\n",
            "112/112 [==============================] - 0s 243us/sample - loss: 0.0747 - accuracy: 0.9732 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 477/500\n",
            "112/112 [==============================] - 0s 261us/sample - loss: 0.0745 - accuracy: 0.9732 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 478/500\n",
            "112/112 [==============================] - 0s 268us/sample - loss: 0.0746 - accuracy: 0.9732 - val_loss: 0.0474 - val_accuracy: 1.0000\n",
            "Epoch 479/500\n",
            "112/112 [==============================] - 0s 314us/sample - loss: 0.0743 - accuracy: 0.9732 - val_loss: 0.0472 - val_accuracy: 1.0000\n",
            "Epoch 480/500\n",
            "112/112 [==============================] - 0s 214us/sample - loss: 0.0742 - accuracy: 0.9732 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 481/500\n",
            "112/112 [==============================] - 0s 185us/sample - loss: 0.0740 - accuracy: 0.9732 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 482/500\n",
            "112/112 [==============================] - 0s 220us/sample - loss: 0.0739 - accuracy: 0.9732 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 483/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.0737 - accuracy: 0.9732 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 484/500\n",
            "112/112 [==============================] - 0s 268us/sample - loss: 0.0735 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 485/500\n",
            "112/112 [==============================] - 0s 215us/sample - loss: 0.0734 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 486/500\n",
            "112/112 [==============================] - 0s 239us/sample - loss: 0.0732 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 487/500\n",
            "112/112 [==============================] - 0s 224us/sample - loss: 0.0732 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 488/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.0730 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 489/500\n",
            "112/112 [==============================] - 0s 232us/sample - loss: 0.0731 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 490/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.0728 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 491/500\n",
            "112/112 [==============================] - 0s 201us/sample - loss: 0.0727 - accuracy: 0.9732 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 492/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.0725 - accuracy: 0.9732 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 493/500\n",
            "112/112 [==============================] - 0s 206us/sample - loss: 0.0724 - accuracy: 0.9732 - val_loss: 0.0471 - val_accuracy: 1.0000\n",
            "Epoch 494/500\n",
            "112/112 [==============================] - 0s 272us/sample - loss: 0.0722 - accuracy: 0.9732 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 495/500\n",
            "112/112 [==============================] - 0s 230us/sample - loss: 0.0721 - accuracy: 0.9732 - val_loss: 0.0469 - val_accuracy: 1.0000\n",
            "Epoch 496/500\n",
            "112/112 [==============================] - 0s 271us/sample - loss: 0.0721 - accuracy: 0.9732 - val_loss: 0.0470 - val_accuracy: 1.0000\n",
            "Epoch 497/500\n",
            "112/112 [==============================] - 0s 322us/sample - loss: 0.0722 - accuracy: 0.9732 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
            "Epoch 498/500\n",
            "112/112 [==============================] - 0s 210us/sample - loss: 0.0718 - accuracy: 0.9732 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
            "Epoch 499/500\n",
            "112/112 [==============================] - 0s 209us/sample - loss: 0.0716 - accuracy: 0.9732 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
            "Epoch 500/500\n",
            "112/112 [==============================] - 0s 184us/sample - loss: 0.0716 - accuracy: 0.9732 - val_loss: 0.0459 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs42eFONh-K0",
        "colab_type": "text"
      },
      "source": [
        "**Test Model**\n",
        "\n",
        "(make predictions)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6HpY8ziLVA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "5abd37a3-7e6a-4b7a-9c45-89daa6402e76"
      },
      "source": [
        "# make class predictions with the model\n",
        "predictions = model.predict_classes( X_test )\n",
        "# predictions = model.predict( X_test )\n",
        "\n",
        "# summarize the first 5 cases\n",
        "for i in range( 0, len(predictions) ):\n",
        "  items = y_test[i]\n",
        "  expected = get_class( items )\n",
        "  prediction = predictions[i]\n",
        "  result = \"\"\n",
        "  if prediction == expected:\n",
        "    result = \"MATCH\"\n",
        "  else:\n",
        "    result = \"     \"\n",
        "  print( \"%d) [%s]  expected:%d  prediction:%d  X_test[%d]:%s\" % ( i, result, expected, prediction, i, X_test[i].tolist() ) )\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0) [MATCH]  expected:1  prediction:1  X_test[0]:[0.310997534138703, -0.5923730118389191, 0.5354085615261401, 0.0008775478952676988]\n",
            "1) [MATCH]  expected:0  prediction:0  X_test[1]:[-0.1736739476359015, 1.7095946507475455, -1.169714245881954, -1.18381211071744]\n",
            "2) [MATCH]  expected:2  prediction:2  X_test[2]:[2.249683461237124, -1.0527665443562113, 1.7858319536254093, 1.448831575088577]\n",
            "3) [MATCH]  expected:1  prediction:1  X_test[3]:[0.18982966369505214, -0.36217624558027245, 0.42173370769893376, 0.3957741007661703]\n",
            "4) [MATCH]  expected:1  prediction:1  X_test[4]:[1.1591726272442622, -0.5923730118389191, 0.5922459884397431, 0.2641419164758693]\n",
            "5) [MATCH]  expected:0  prediction:0  X_test[5]:[-0.5371775589668552, 0.7888075857129598, -1.2833890997091604, -1.052179926427139]\n",
            "6) [MATCH]  expected:1  prediction:1  X_test[6]:[-0.29484181807955345, -0.36217624558027245, -0.08980313452349442, 0.13250973218556866]\n",
            "7) [MATCH]  expected:2  prediction:2  X_test[7]:[1.2803404976879142, 0.09821728693702086, 0.7627582691805523, 1.448831575088577]\n",
            "8) [MATCH]  expected:1  prediction:1  X_test[8]:[0.4321654045823549, -1.973553609390797, 0.42173370769893376, 0.3957741007661703]\n",
            "9) [MATCH]  expected:1  prediction:1  X_test[9]:[-0.052506077192250644, -0.8225697780975647, 0.08070914621731488, 0.0008775478952676988]\n",
            "10) [MATCH]  expected:2  prediction:2  X_test[10]:[0.7956690159133086, 0.3284140531956675, 0.7627582691805523, 1.0539350222176747]\n",
            "11) [MATCH]  expected:0  prediction:0  X_test[11]:[-1.2641847816287635, -0.1319794793216258, -1.3402265266227635, -1.4470764792980415]\n",
            "12) [MATCH]  expected:0  prediction:0  X_test[12]:[-0.4160096885232043, 1.0190043519716065, -1.3970639535363667, -1.3154442950077407]\n",
            "13) [MATCH]  expected:0  prediction:0  X_test[13]:[-1.1430169111851116, 0.09821728693702086, -1.2833890997091604, -1.4470764792980415]\n",
            "14) [MATCH]  expected:0  prediction:0  X_test[14]:[-0.9006811702978099, 1.7095946507475455, -1.2833890997091604, -1.18381211071744]\n",
            "15) [MATCH]  expected:1  prediction:1  X_test[15]:[0.5533332750260058, 0.5586108194543131, 0.5354085615261401, 0.5274062850564712]\n",
            "16) [MATCH]  expected:2  prediction:2  X_test[16]:[0.7956690159133086, -0.1319794793216258, 1.1606202575757745, 1.3171993907982766]\n",
            "17) [MATCH]  expected:1  prediction:1  X_test[17]:[-0.29484181807955345, -1.282963310614858, 0.08070914621731488, -0.13075463639503299]\n",
            "18) [MATCH]  expected:1  prediction:1  X_test[18]:[-0.1736739476359015, -0.5923730118389191, 0.42173370769893376, 0.13250973218556866]\n",
            "19) [MATCH]  expected:2  prediction:2  X_test[19]:[0.6745011454696578, -0.5923730118389191, 1.0469454037485681, 1.3171993907982766]\n",
            "20) [MATCH]  expected:0  prediction:0  X_test[20]:[-1.3853526520724144, 0.3284140531956675, -1.2265516727955572, -1.3154442950077407]\n",
            "21) [MATCH]  expected:2  prediction:2  X_test[21]:[0.310997534138703, -0.1319794793216258, 0.6490834153533465, 0.7906706536370729]\n",
            "22) [MATCH]  expected:0  prediction:0  X_test[22]:[-1.0218490407414607, 0.7888075857129598, -1.2265516727955572, -1.052179926427139]\n",
            "23) [MATCH]  expected:2  prediction:2  X_test[23]:[0.6745011454696578, -0.5923730118389191, 1.0469454037485681, 1.1855672065079756]\n",
            "24) [MATCH]  expected:2  prediction:2  X_test[24]:[2.492019202124427, 1.7095946507475455, 1.5016448190573937, 1.0539350222176747]\n",
            "25) [MATCH]  expected:2  prediction:2  X_test[25]:[1.0380047568006114, -0.1319794793216258, 0.8195956960941558, 1.448831575088577]\n",
            "26) [MATCH]  expected:2  prediction:2  X_test[26]:[1.0380047568006114, -1.282963310614858, 1.1606202575757745, 0.7906706536370729]\n",
            "27) [MATCH]  expected:2  prediction:2  X_test[27]:[1.1591726272442622, 0.3284140531956675, 1.2174576844893779, 1.448831575088577]\n",
            "28) [MATCH]  expected:0  prediction:0  X_test[28]:[-1.2641847816287635, -0.1319794793216258, -1.3402265266227635, -1.18381211071744]\n",
            "29) [MATCH]  expected:0  prediction:0  X_test[29]:[-1.2641847816287635, 0.09821728693702086, -1.2265516727955572, -1.3154442950077407]\n",
            "30) [MATCH]  expected:0  prediction:0  X_test[30]:[-1.5065205225160663, 1.2492011182302531, -1.567576234277176, -1.3154442950077407]\n",
            "31) [MATCH]  expected:0  prediction:0  X_test[31]:[-0.1736739476359015, 3.0907752482994253, -1.2833890997091604, -1.052179926427139]\n",
            "32) [MATCH]  expected:1  prediction:1  X_test[32]:[1.0380047568006114, 0.09821728693702086, 0.3648962807853308, 0.2641419164758693]\n",
            "33) [MATCH]  expected:0  prediction:0  X_test[33]:[-1.2641847816287635, 0.7888075857129598, -1.2265516727955572, -1.3154442950077407]\n",
            "34) [MATCH]  expected:0  prediction:0  X_test[34]:[-1.748856263403368, 0.3284140531956675, -1.3970639535363667, -1.3154442950077407]\n",
            "35) [MATCH]  expected:2  prediction:2  X_test[35]:[0.5533332750260058, -1.282963310614858, 0.7059208422669494, 0.9223028379273737]\n",
            "36) [MATCH]  expected:1  prediction:1  X_test[36]:[0.6745011454696578, 0.3284140531956675, 0.42173370769893376, 0.3957741007661703]\n",
            "37) [MATCH]  expected:0  prediction:0  X_test[37]:[-0.779513299854158, 1.0190043519716065, -1.2833890997091604, -1.3154442950077407]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAwGY3Zj8QKJ",
        "colab_type": "text"
      },
      "source": [
        "### MNIST (recognize objects in images)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC2Luan9LAC7",
        "colab_type": "text"
      },
      "source": [
        "Build \"Model\" using Keras, which calls TensorFlow implementation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9oUjtELPyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential(\n",
        "    [\n",
        "     tf.keras.layers.Flatten( input_shape=[28, 28] )\n",
        "    #  , tf.keras.layers.Dense( 128, activation='relu' )\n",
        "    #  , tf.keras.layers.Dropout( 0.2 )\n",
        "     , tf.keras.layers.Dense( 10, activation='softmax' )\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer = 'adam'\n",
        "    , loss = 'sparse_categorical_crossentropy'\n",
        "    , metrics = [ 'accuracy' ]\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "plot = tf.keras.utils.plot_model( model, 'skip_connection.png', show_shapes=True )\n",
        "\n",
        "plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPi9Mlf9MlT7",
        "colab_type": "text"
      },
      "source": [
        "Train & evaluate model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlBbIFpkMr1B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_history = model.fit( X_train, y_train, validation_data=(X_test, y_test), epochs=5 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FY5becXlZ3ax",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_results = model.evaluate( X_test, y_test )\n",
        "eval_results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9Iq7wPGSRov",
        "colab_type": "text"
      },
      "source": [
        "Visualize Learned Network \"Weights\":"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxLgJiWfSXjq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from  matplotlib.colors import LinearSegmentedColormap\n",
        "\n",
        "model.summary()\n",
        "\n",
        "def  show_layer_weights(p_digit_number):\n",
        "  dense_layer = model.layers[1]\n",
        "  weights_inspect = dense_layer.get_weights()[0]\n",
        "  dense_layer_weights = []\n",
        "  for connection in weights_inspect:\n",
        "    weight = connection[ p_digit_number ]\n",
        "    dense_layer_weights.append( weight )\n",
        "  dense_layer_weights\n",
        "  img = tf.reshape( dense_layer_weights, [28, 28] )\n",
        "  # plt.imshow( img, cmap = cmap )\n",
        "  return img\n",
        "\n",
        "fig, axes = plt.subplots( 2, 5, figsize=(10, 4) )\n",
        "fig.tight_layout()\n",
        "axes = axes.reshape(-1)\n",
        "for digit_number in range( 0, 10 ):\n",
        "  title = \"Digit \" + str( digit_number )\n",
        "  a = axes[ digit_number ]\n",
        "  img = show_layer_weights( digit_number )\n",
        "  cmap = LinearSegmentedColormap.from_list( 'rg', [\"red\", \"lightgray\", \"green\"], N=256 )\n",
        "  a.imshow( img, cmap = cmap )\n",
        "  a.set_title( title )\n",
        "  a.set_xticks(()) # ticks be gone\n",
        "  a.set_yticks(())\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnCxtqeaOu8m",
        "colab_type": "text"
      },
      "source": [
        "## Chart the Model's \"Learning\" progress:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgHN65-0OxW8",
        "colab_type": "code",
        "outputId": "4d903d53-df9f-4b0c-b1df-1c6ef7fa8a59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "source": [
        "# Chart training progress\n",
        "plot_training_progress( training_history )"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niXCWCIwxJsJZIjDGmAj3/wGwFxEtTzGWYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqqRNjbXZE5F",
        "colab_type": "text"
      },
      "source": [
        "## Convolution"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vpydVkfgZTE1",
        "colab_type": "text"
      },
      "source": [
        "Setup..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSMzXHCZV5e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from skimage  import color, data\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%tensorflow_version  2.x\n",
        "import  tensorflow  as  tf\n",
        "print( tf.__version__ )\n",
        "\n",
        "from  tensorflow.keras  import Model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6o37uPGIbeK5",
        "colab_type": "text"
      },
      "source": [
        "Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFDwubQ5bl3T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img = data.astronaut()\n",
        "img = color.rgb2gray( img )\n",
        "plt.axis( 'off' )\n",
        "plt.imshow( img, cmap=plt.cm.gray )\n",
        "plt.title( 'Eileen Collins, 1st Woman Shuttle Commander' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0hsav6XaqkH",
        "colab_type": "text"
      },
      "source": [
        "Build Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNZrxfGJavzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Conv2D( name = 'Edges_from_Pixels'\n",
        "        , filters = 4\n",
        "        , kernel_size = ( 4, 4 )\n",
        "        , input_shape = ( 10, 10, 3 )\n",
        "    )\n",
        ")\n",
        "\n",
        "model.add(\n",
        "    tf.keras.layers.Conv2D( name = 'Shapes_from_Edges'\n",
        "        , filters = 8\n",
        "        , kernel_size = ( 3, 3 )\n",
        "    )\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "tf.keras.utils.plot_model( model, 'skip_connection.png', show_shapes=True )\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}